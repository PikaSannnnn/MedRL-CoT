{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89d5679-991e-4f17-bcdf-a39beef3ef0e",
   "metadata": {},
   "source": [
    "### Preprocessing for Mimic4 Dataset\n",
    "\n",
    "**Note that the AUG dataset is incomplete, so we skip it here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "02e50ca3-9850-42d7-b71f-8390c9a90dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medrlcot.config.env import MedRL_CoT\n",
    "from medrlcot import data_manager\n",
    "from medrlcot.medrlcot_logger import setup_logger\n",
    "from dotenv import load_dotenv\n",
    "from datasets import Features, Value\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets as hf_datasets\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)  \n",
    "# pd.set_option('display.width', 0)    \n",
    "# pd.set_option('display.max_rows', None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "36a0e936-71fc-48ac-b099-6f3050346a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 14:09:03,636 || INFO || Logger - Setup for MedRL-CoT's log done. This is the beginning of the log.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated new log file logs/medrlcot079.log\n"
     ]
    }
   ],
   "source": [
    "model_cfg_path = os.path.join(os.getcwd(), \"medrlcot/config/.env\")\n",
    "medrlcot_config = MedRL_CoT(model_cfg_path)\n",
    "\n",
    "setup_logger()\n",
    "logger = logging.getLogger(\"MedRL-CoT Preprocess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "86c6e504-937a-4abe-9c61-aa5c59490b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aug_med_notes', 'mimic4'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processed_dirs = [os.path.join(os.getcwd(), medrlcot_config.data_dir, ds, 'processed') for ds in medrlcot_config.datasets]\n",
    "processed_dirs = {ds: os.path.join(os.getcwd(), medrlcot_config.data_dir, ds, 'processed') for ds in medrlcot_config.datasets}\n",
    "processed_dirs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "499d4653-c605-406c-ad24-a1580c7e1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(['symptoms_labs', 'thought_process', 'diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee7871d1-58d9-4dd2-86ed-e4b44df82554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labeled(arrow_dir):\n",
    "    arrows = [os.path.join(arrow_dir, f) for f in os.listdir(arrow_dir) if f.endswith(\".arrow\")]\n",
    "    processed_dataset = hf_datasets.concatenate_datasets([hf_datasets.Dataset.from_file(arrow) for arrow in arrows]).to_dict()\n",
    "\n",
    "    return processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f7b55fa0-aabe-4327-ac1f-b59a26e9d07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aug_med_notes', 'mimic4'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_datasets = {key: pd.DataFrame(load_labeled(processed_dir)) for key, processed_dir in processed_dirs.items()}\n",
    "processed_datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "a03decef-49ea-4bfe-98be-b5765f7876e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 17:42:33,392 || INFO || MedRL-CoT Preprocess - Found 29654 rows\n",
      "2025-06-02 17:42:33,394 || INFO || MedRL-CoT Preprocess - Fixed class naming for 282 rows (0.9509678289606799 %)\n",
      "2025-06-02 17:42:33,420 || INFO || MedRL-CoT Preprocess - Re-classified 18 classes as 'other', or 1076 rows (3.628515545963445 %)\n",
      "2025-06-02 17:42:33,421 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 571 rows (1.925541242328185 %)\n",
      "2025-06-02 17:42:33,423 || INFO || MedRL-CoT Preprocess - Dropped 166 invalid rows (0.5597895730761449 %)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "      <th>case_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>History of Present Illness:</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pt reports self-discontinuing lasix and spirno...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She does not follow Na-restricted diets.</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the past week, she notes that she has been ...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>She denies ___ edema, or SOB, or orthopnea.</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29649</th>\n",
       "      <td>Please call cardiac surgery office with any qu...</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29650</th>\n",
       "      <td>Patient presented with a chief complaint of ch...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29651</th>\n",
       "      <td>The ECG showed no signs of ischemia.</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29652</th>\n",
       "      <td>The patient's history of hypertension and hype...</td>\n",
       "      <td>thought_process</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29653</th>\n",
       "      <td>A diagnosis of stable angina was made.</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29488 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence            class  \\\n",
       "0                            History of Present Illness:    symptoms_labs   \n",
       "1      Pt reports self-discontinuing lasix and spirno...    symptoms_labs   \n",
       "2               She does not follow Na-restricted diets.    symptoms_labs   \n",
       "3      In the past week, she notes that she has been ...    symptoms_labs   \n",
       "4            She denies ___ edema, or SOB, or orthopnea.    symptoms_labs   \n",
       "...                                                  ...              ...   \n",
       "29649  Please call cardiac surgery office with any qu...        diagnosis   \n",
       "29650  Patient presented with a chief complaint of ch...    symptoms_labs   \n",
       "29651               The ECG showed no signs of ischemia.    symptoms_labs   \n",
       "29652  The patient's history of hypertension and hype...  thought_process   \n",
       "29653             A diagnosis of stable angina was made.        diagnosis   \n",
       "\n",
       "      case_id  \n",
       "0          -1  \n",
       "1          -1  \n",
       "2          -1  \n",
       "3          -1  \n",
       "4          -1  \n",
       "...       ...  \n",
       "29649     283  \n",
       "29650     283  \n",
       "29651     283  \n",
       "29652     283  \n",
       "29653     283  \n",
       "\n",
       "[29488 rows x 3 columns]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mimic_preprocess(dataset):\n",
    "    cleaned_ds = dataset.copy()\n",
    "\n",
    "    # For loggin purposes\n",
    "    N = cleaned_ds.shape[0]\n",
    "    logger.info(f\"Found {N} rows\")\n",
    "    num_renames = cleaned_ds[cleaned_ds['class'].isin(['symptoms_lbs', 'symptoms_lads'])].shape[0]\n",
    "    logger.info(f\"Fixed class naming for {num_renames} rows ({(num_renames / N)*100} %)\")\n",
    "    \n",
    "    # Fix naming of some classes\n",
    "    cleaned_ds['class'] = cleaned_ds['class'].replace({'symptoms_lbs': 'symptoms_labs', 'symptoms_lads': 'symptoms_labs'})\n",
    "    \n",
    "    pos_invalids = cleaned_ds[~cleaned_ds['class'].isin(classes)]\n",
    "    swapped_values = pos_invalids[pos_invalids['sentence'].str.lower().isin(classes)]    # Rows with swapped values\n",
    "    \n",
    "    # Clearly invalids, temp drop to remove from our ceaned list\n",
    "    invalid_classes = pos_invalids[pos_invalids['class'].str.lower().isin(['', '0', '__', 'None'])]  # collect empty sentence and classes (Note that doing it here will catch the invalid swapped sentences as well)\n",
    "    invalid_sentences = pos_invalids[pos_invalids['sentence'].str.lower().isin(['', '__', 'None'])]\n",
    "    invalids = pos_invalids.loc[invalid_classes.index.union(invalid_sentences.index)]\n",
    "    nonstd_classes = pos_invalids.drop(index=swapped_values.index.union(invalids.index))   # Get list of non-standard classes\n",
    "\n",
    "    # Get list of classes that can be classified as \"other\" with enough occurence (non-outliery)\n",
    "    value_cnts = nonstd_classes['class'].value_counts()\n",
    "    other_classes = value_cnts[value_cnts >= 5].index.tolist()\n",
    "    # print(value_cnts[value_cnts >= 5])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'past_surgical_history'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'followup_instructions'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'demographic_data'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'past_surgical_history'])\n",
    "    \n",
    "    # Clean the dataset\n",
    "    swapped_indices = swapped_values.index\n",
    "    cleaned_ds.loc[swapped_indices, ['sentence', 'class']] = cleaned_ds.loc[swapped_indices, ['class', 'sentence']].values # swap the values in indices where it's swapped\n",
    "    cleaned_ds['class'] = cleaned_ds['class'].apply(lambda x: 'other' if x in other_classes else x)  # relabel non-standards to 'other'\n",
    "    drop_indices = cleaned_ds[~cleaned_ds['class'].isin(np.append(classes, 'other'))].index\n",
    "    cleaned_ds = cleaned_ds.drop(index=drop_indices) # drop all others that aren't in our list of classes + 'other'  (basically all invalids)\n",
    "\n",
    "    # Summary\n",
    "    num_reclass = cleaned_ds[cleaned_ds['class'] == 'other'].shape[0]\n",
    "    logger.info(f\"Re-classified {len(other_classes)} classes as 'other', or {num_reclass} rows ({(num_reclass / N)*100} %)\")\n",
    "    logger.info(f'Swapped class and sentence values of {swapped_indices.shape[0]} rows ({(swapped_indices.shape[0] / N)*100} %)')\n",
    "    logger.info(f'Dropped {drop_indices.shape[0]} invalid rows ({(drop_indices.shape[0] / N)*100} %)')\n",
    "\n",
    "    return cleaned_ds\n",
    "\n",
    "mimic_preprocess(processed_datasets['mimic4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "f58e2d2b-b3ac-4d4a-86c2-4cecc94f1fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 17:42:21,243 || INFO || MedRL-CoT Preprocess - Found 19968 rows\n",
      "2025-06-02 17:42:21,246 || INFO || MedRL-CoT Preprocess - Fixed class naming for 21 rows (0.10516826923076923 %)\n",
      "2025-06-02 17:42:21,272 || INFO || MedRL-CoT Preprocess - Re-classified 5 classes as 'other', or 77 rows (0.3856169871794872 %)\n",
      "2025-06-02 17:42:21,274 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 131 rows (0.6560496794871795 %)\n",
      "2025-06-02 17:42:21,275 || INFO || MedRL-CoT Preprocess - Dropped 163 invalid rows (0.8163060897435898 %)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "      <th>case_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A sixteen year-old girl, presented to our Outp...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She was not able to maintain an erect posture ...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She would keep her head turned to the right an...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There was a sideways bending of the back in th...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To counter the abnormal positioning of the bac...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19963</th>\n",
       "      <td>No significant muscle atrophy was present, and...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19964</th>\n",
       "      <td>The physical examination showed that both of h...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19965</th>\n",
       "      <td>Both knees were very soft and could touch the ...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19966</th>\n",
       "      <td>Upon palpation, the continuity of the quadrice...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19967</th>\n",
       "      <td>In addition, the patient could not complete kn...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19805 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence          class  \\\n",
       "0      A sixteen year-old girl, presented to our Outp...  symptoms_labs   \n",
       "1      She was not able to maintain an erect posture ...  symptoms_labs   \n",
       "2      She would keep her head turned to the right an...  symptoms_labs   \n",
       "3      There was a sideways bending of the back in th...  symptoms_labs   \n",
       "4      To counter the abnormal positioning of the bac...  symptoms_labs   \n",
       "...                                                  ...            ...   \n",
       "19963  No significant muscle atrophy was present, and...  symptoms_labs   \n",
       "19964  The physical examination showed that both of h...  symptoms_labs   \n",
       "19965  Both knees were very soft and could touch the ...  symptoms_labs   \n",
       "19966  Upon palpation, the continuity of the quadrice...  symptoms_labs   \n",
       "19967  In addition, the patient could not complete kn...  symptoms_labs   \n",
       "\n",
       "      case_id  \n",
       "0          -1  \n",
       "1          -1  \n",
       "2          -1  \n",
       "3          -1  \n",
       "4          -1  \n",
       "...       ...  \n",
       "19963     912  \n",
       "19964     915  \n",
       "19965     915  \n",
       "19966     915  \n",
       "19967     915  \n",
       "\n",
       "[19805 rows x 3 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def aug_preprocess(dataset):\n",
    "    cleaned_ds = dataset.copy()\n",
    "\n",
    "    # For loggin purposes\n",
    "    N = cleaned_ds.shape[0]\n",
    "    logger.info(f\"Found {N} rows\")\n",
    "    num_renames = cleaned_ds[cleaned_ds['class'].isin(['symptoms_lbs', 'symptoms_lads'])].shape[0]\n",
    "    logger.info(f\"Fixed class naming for {num_renames} rows ({(num_renames / N)*100} %)\")\n",
    "    \n",
    "    # Fix naming of some classes\n",
    "    cleaned_ds['class'] = cleaned_ds['class'].replace({'symptoms_lbs': 'symptoms_labs', 'symptoms_lads': 'symptoms_labs'})\n",
    "    \n",
    "    pos_invalids = cleaned_ds[~cleaned_ds['class'].isin(classes)]\n",
    "    swapped_values = pos_invalids[pos_invalids['sentence'].isin(classes)]    # Rows with swapped values\n",
    "    invalid_classes = pos_invalids[pos_invalids['class'].str.lower().isin(['', '0', '__', 'None', '[]', 'False', 'The', 'No'])]  # collect empty sentence and classes (Note that doing it here will catch the invalid swapped sentences as well)\n",
    "    # ignore_classes = pos_invalids[pos_invalids['class'].str.contains('not a sentence')]\n",
    "    invalid_sentences = pos_invalids[pos_invalids['sentence'].str.lower().isin(['', '__', 'None', '[]', 'False', '()'])]\n",
    "    \n",
    "    # invalids = pos_invalids.loc[invalid_classes.index.union(invalid_sentences.index.union(ignore_classes.index))]\n",
    "    invalids = pos_invalids.loc[invalid_classes.index.union(invalid_sentences.index)]\n",
    "    # invalids = pos_invalids[pos_invalids ['class'].isin(['', '0', '[]', 'False'])]   # Clearly invalids, temp drop to remove from our ceaned list\n",
    "    nonstd_classes = pos_invalids.drop(index=swapped_values.index.union(invalids.index))   # Get list of non-standard classes\n",
    "\n",
    "    # Get list of classes that can be classified as \"other\" with enough occurence (non-outliery)\n",
    "    value_cnts = nonstd_classes['class'].value_counts()\n",
    "    other_classes = value_cnts[value_cnts >= 5].index.tolist()\n",
    "    # print(value_cnts[value_cnts >= 5])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'symptoms_lbs'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'A'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'classification'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'No'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'The'])\n",
    "\n",
    "    swapped_indices = swapped_values.index\n",
    "    cleaned_ds.loc[swapped_indices, ['sentence', 'class']] = cleaned_ds.loc[swapped_indices, ['class', 'sentence']].values # swap the values in indices where it's swapped\n",
    "    cleaned_ds['class'] = cleaned_ds['class'].apply(lambda x: 'other' if x in other_classes else x)  # relabel non-standards to 'other'\n",
    "    drop_indices = cleaned_ds[~cleaned_ds['class'].isin(np.append(classes, 'other'))].index\n",
    "    cleaned_ds = cleaned_ds.drop(index=drop_indices) # drop all others that aren't in our list of classes + 'other' (basically all invalids)\n",
    "\n",
    "    # Summary\n",
    "    num_reclass = cleaned_ds[cleaned_ds['class'] == 'other'].shape[0]\n",
    "    logger.info(f\"Re-classified {len(other_classes)} classes as 'other', or {num_reclass} rows ({(num_reclass / N)*100} %)\")\n",
    "    logger.info(f'Swapped class and sentence values of {swapped_indices.shape[0]} rows ({(swapped_indices.shape[0] / N)*100} %)')\n",
    "    logger.info(f'Dropped {drop_indices.shape[0]} invalid rows ({(drop_indices.shape[0] / N)*100} %)')\n",
    "    \n",
    "    return cleaned_ds\n",
    "\n",
    "aug_preprocess(processed_datasets['aug_med_notes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "5643b621-e1f5-48c4-b7b6-69a0c4569c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "proc_funcs = {'mimic4': mimic_preprocess, 'aug_med_notes': aug_preprocess}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "2dc24bb2-7506-4e5a-9115-a2951271fbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 17:47:33,632 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "2025-06-02 17:47:33,791 || INFO || MedRL-CoT Preprocess - Cleaning up aug_med_notes dataset\n",
      "2025-06-02 17:47:33,802 || INFO || MedRL-CoT Preprocess - Found 19968 rows\n",
      "2025-06-02 17:47:33,806 || INFO || MedRL-CoT Preprocess - Fixed class naming for 21 rows (0.10516826923076923 %)\n",
      "2025-06-02 17:47:33,840 || INFO || MedRL-CoT Preprocess - Re-classified 5 classes as 'other', or 77 rows (0.3856169871794872 %)\n",
      "2025-06-02 17:47:33,842 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 131 rows (0.6560496794871795 %)\n",
      "2025-06-02 17:47:33,842 || INFO || MedRL-CoT Preprocess - Dropped 163 invalid rows (0.8163060897435898 %)\n",
      "2025-06-02 17:47:33,844 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "2025-06-02 17:47:33,845 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "2025-06-02 17:47:33,847 || INFO || MedRL-CoT Preprocess - Cleaning up mimic4 dataset\n",
      "2025-06-02 17:47:33,850 || INFO || MedRL-CoT Preprocess - Found 29654 rows\n",
      "2025-06-02 17:47:33,853 || INFO || MedRL-CoT Preprocess - Fixed class naming for 282 rows (0.9509678289606799 %)\n",
      "2025-06-02 17:47:33,886 || INFO || MedRL-CoT Preprocess - Re-classified 18 classes as 'other', or 1076 rows (3.628515545963445 %)\n",
      "2025-06-02 17:47:33,888 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 571 rows (1.925541242328185 %)\n",
      "2025-06-02 17:47:33,889 || INFO || MedRL-CoT Preprocess - Dropped 166 invalid rows (0.5597895730761449 %)\n",
      "2025-06-02 17:47:33,890 || INFO || MedRL-CoT Preprocess - ==================================================\n"
     ]
    }
   ],
   "source": [
    "preprocessed_datasets = dict()\n",
    "for key, item in processed_datasets.items():\n",
    "    logger.info(\"=\" * 50)\n",
    "    logger.info(f\"Cleaning up {key} dataset\")\n",
    "    # processed_datasets[key] = mimic_preprocess(processed_datasets[key])\n",
    "    # mimic_preprocess(processed_datasets[key])\n",
    "    preprocessed_datasets[key] = proc_funcs[key](processed_datasets[key])\n",
    "    logger.info(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "970f8205-b8fb-4fd7-8c7a-1bb540cd4085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aug_med_notes', 'mimic4'])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d24b4d-a85e-4078-9027-b7211f215ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
