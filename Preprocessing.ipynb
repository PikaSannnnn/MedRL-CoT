{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89d5679-991e-4f17-bcdf-a39beef3ef0e",
   "metadata": {},
   "source": [
    "### Preprocessing for Mimic4 Dataset\n",
    "\n",
    "**Note that the AUG dataset is incomplete, so we skip it here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52ad5779-a5ac-4867-9b7f-fc3023047b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e50ca3-9850-42d7-b71f-8390c9a90dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medrlcot.config.env import MedRL_CoT\n",
    "from medrlcot import data_manager\n",
    "from medrlcot.medrlcot_logger import setup_logger\n",
    "from dotenv import load_dotenv\n",
    "from datasets import Features, Value\n",
    "import torch\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets as hf_datasets\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)  \n",
    "# pd.set_option('display.width', 0)    \n",
    "# pd.set_option('display.max_rows', None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a0e936-71fc-48ac-b099-6f3050346a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 01:58:52,214 || INFO || Logger - Setup for MedRL-CoT's log done. This is the beginning of the log.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated new log file logs/medrlcot144.log\n"
     ]
    }
   ],
   "source": [
    "model_cfg_path = os.path.join(os.getcwd(), \"medrlcot/config/.env\")\n",
    "medrlcot_config = MedRL_CoT(model_cfg_path)\n",
    "\n",
    "setup_logger()\n",
    "logger = logging.getLogger(\"MedRL-CoT Preprocess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c6e504-937a-4abe-9c61-aa5c59490b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aug_med_notes', 'mimic4'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processed_dirs = [os.path.join(os.getcwd(), medrlcot_config.data_dir, ds, 'processed') for ds in medrlcot_config.datasets]\n",
    "processed_dirs = {ds: os.path.join(os.getcwd(), medrlcot_config.data_dir, ds, 'processed') for ds in medrlcot_config.datasets}\n",
    "processed_dirs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "499d4653-c605-406c-ad24-a1580c7e1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(['symptoms_labs', 'thought_process', 'diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7871d1-58d9-4dd2-86ed-e4b44df82554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labeled(arrow_dir):\n",
    "    arrows = [os.path.join(arrow_dir, f) for f in os.listdir(arrow_dir) if f.endswith(\".arrow\")]\n",
    "    processed_dataset = hf_datasets.concatenate_datasets([hf_datasets.Dataset.from_file(arrow) for arrow in arrows]).to_dict()\n",
    "\n",
    "    return processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7b55fa0-aabe-4327-ac1f-b59a26e9d07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aug_med_notes', 'mimic4'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_datasets = {key: pd.DataFrame(load_labeled(processed_dir)) for key, processed_dir in processed_dirs.items()}\n",
    "processed_datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a03decef-49ea-4bfe-98be-b5765f7876e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 01:58:52,634 || INFO || MedRL-CoT Preprocess - Found 29654 rows\n",
      "2025-06-04 01:58:52,637 || INFO || MedRL-CoT Preprocess - Fixed class naming for 282 rows (0.9509678289606799 %)\n",
      "2025-06-04 01:58:52,654 || INFO || MedRL-CoT Preprocess - Re-classified 18 classes as 'other', or 1073 rows (3.618398866931948 %)\n",
      "2025-06-04 01:58:52,655 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 571 rows (1.925541242328185 %)\n",
      "2025-06-04 01:58:52,656 || INFO || MedRL-CoT Preprocess - Dropped 169 invalid rows (0.5699062521076415 %)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "symptoms_labs      16680\n",
       "diagnosis           9112\n",
       "thought_process     2620\n",
       "other               1073\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mimic_preprocess(dataset):\n",
    "    cleaned_ds = dataset.copy()\n",
    "\n",
    "    # For loggin purposes\n",
    "    N = cleaned_ds.shape[0]\n",
    "    logger.info(f\"Found {N} rows\")\n",
    "    num_renames = cleaned_ds[cleaned_ds['class'].isin(['symptoms_lbs', 'symptoms_lads'])].shape[0]\n",
    "    logger.info(f\"Fixed class naming for {num_renames} rows ({(num_renames / N)*100} %)\")\n",
    "    \n",
    "    # Fix naming of some classes\n",
    "    cleaned_ds['class'] = cleaned_ds['class'].replace({'symptoms_lbs': 'symptoms_labs', 'symptoms_lads': 'symptoms_labs'})\n",
    "    \n",
    "    pos_invalids = cleaned_ds[~cleaned_ds['class'].isin(classes)]\n",
    "    swapped_values = pos_invalids[pos_invalids['sentence'].str.lower().isin(classes)]    # Rows with swapped values\n",
    "    \n",
    "    # Clearly invalids, temp drop to remove from our ceaned list\n",
    "    invalid_classes = pos_invalids[pos_invalids['class'].str.lower().isin(['', '0', '__', 'None'])]  # collect empty sentence and classes (Note that doing it here will catch the invalid swapped sentences as well)\n",
    "    invalid_sentences = pos_invalids[pos_invalids['sentence'].str.lower().isin(['', '__', 'None'])]\n",
    "    invalids = pos_invalids.loc[invalid_classes.index.union(invalid_sentences.index)]\n",
    "    nonstd_classes = pos_invalids.drop(index=swapped_values.index.union(invalids.index))   # Get list of non-standard classes\n",
    "\n",
    "    # Get list of classes that can be classified as \"other\" with enough occurence (non-outliery)\n",
    "    # value_cnts = nonstd_classes['class'].value_counts()\n",
    "    # other_classes = value_cnts[value_cnts >= 5].index.tolist()\n",
    "    value_cnts = nonstd_classes['class'].value_counts()\n",
    "    other_classes = value_cnts[value_cnts >= 5].index.tolist()\n",
    "    other_class_indices = nonstd_classes[nonstd_classes['class'].isin(other_classes)].index\n",
    "    # print(value_cnts[value_cnts >= 5])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'past_surgical_history'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'followup_instructions'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'demographic_data'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'past_surgical_history'])\n",
    "    \n",
    "    # Clean the dataset\n",
    "    swapped_indices = swapped_values.index\n",
    "    cleaned_ds.loc[swapped_indices, ['sentence', 'class']] = cleaned_ds.loc[swapped_indices, ['class', 'sentence']].values # swap the values in indices where it's swapped\n",
    "    cleaned_ds.loc[other_class_indices, 'class'] = 'other'\n",
    "    # cleaned_ds['class'] = cleaned_ds['class'].apply(lambda x: 'other' if x in other_classes else x)  # relabel non-standards to 'other'\n",
    "    drop_indices = cleaned_ds[~cleaned_ds['class'].isin(np.append(classes, 'other'))].index\n",
    "    cleaned_ds = cleaned_ds.drop(index=drop_indices) # drop all others that aren't in our list of classes + 'other'  (basically all invalids)\n",
    "\n",
    "    # Summary\n",
    "    num_reclass = cleaned_ds[cleaned_ds['class'] == 'other'].shape[0]\n",
    "    logger.info(f\"Re-classified {len(other_classes)} classes as 'other', or {num_reclass} rows ({(num_reclass / N)*100} %)\")\n",
    "    logger.info(f'Swapped class and sentence values of {swapped_indices.shape[0]} rows ({(swapped_indices.shape[0] / N)*100} %)')\n",
    "    logger.info(f'Dropped {drop_indices.shape[0]} invalid rows ({(drop_indices.shape[0] / N)*100} %)')\n",
    "\n",
    "    # change case_id into int\n",
    "    cleaned_ds['case_id'] = cleaned_ds['case_id'].astype(int)\n",
    "\n",
    "    return cleaned_ds\n",
    "\n",
    "mimic_preprocess(processed_datasets['mimic4'])['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f58e2d2b-b3ac-4d4a-86c2-4cecc94f1fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 01:58:52,708 || INFO || MedRL-CoT Preprocess - Found 19968 rows\n",
      "2025-06-04 01:58:52,712 || INFO || MedRL-CoT Preprocess - Fixed class naming for 21 rows (0.10516826923076923 %)\n",
      "2025-06-04 01:58:52,724 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 131 rows (0.6560496794871795 %)\n",
      "2025-06-04 01:58:52,725 || INFO || MedRL-CoT Preprocess - Dropped 240 invalid rows (1.201923076923077 %)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "      <th>case_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A sixteen year-old girl, presented to our Outp...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She was not able to maintain an erect posture ...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She would keep her head turned to the right an...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There was a sideways bending of the back in th...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To counter the abnormal positioning of the bac...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19963</th>\n",
       "      <td>No significant muscle atrophy was present, and...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19964</th>\n",
       "      <td>The physical examination showed that both of h...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19965</th>\n",
       "      <td>Both knees were very soft and could touch the ...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19966</th>\n",
       "      <td>Upon palpation, the continuity of the quadrice...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19967</th>\n",
       "      <td>In addition, the patient could not complete kn...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19728 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence          class  \\\n",
       "0      A sixteen year-old girl, presented to our Outp...  symptoms_labs   \n",
       "1      She was not able to maintain an erect posture ...  symptoms_labs   \n",
       "2      She would keep her head turned to the right an...  symptoms_labs   \n",
       "3      There was a sideways bending of the back in th...  symptoms_labs   \n",
       "4      To counter the abnormal positioning of the bac...  symptoms_labs   \n",
       "...                                                  ...            ...   \n",
       "19963  No significant muscle atrophy was present, and...  symptoms_labs   \n",
       "19964  The physical examination showed that both of h...  symptoms_labs   \n",
       "19965  Both knees were very soft and could touch the ...  symptoms_labs   \n",
       "19966  Upon palpation, the continuity of the quadrice...  symptoms_labs   \n",
       "19967  In addition, the patient could not complete kn...  symptoms_labs   \n",
       "\n",
       "       case_id  \n",
       "0           -1  \n",
       "1           -1  \n",
       "2           -1  \n",
       "3           -1  \n",
       "4           -1  \n",
       "...        ...  \n",
       "19963      912  \n",
       "19964      915  \n",
       "19965      915  \n",
       "19966      915  \n",
       "19967      915  \n",
       "\n",
       "[19728 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def aug_preprocess(dataset):\n",
    "    cleaned_ds = dataset.copy()\n",
    "\n",
    "    # For loggin purposes\n",
    "    N = cleaned_ds.shape[0]\n",
    "    logger.info(f\"Found {N} rows\")\n",
    "    num_renames = cleaned_ds[cleaned_ds['class'].isin(['symptoms_lbs', 'symptoms_lads'])].shape[0]\n",
    "    logger.info(f\"Fixed class naming for {num_renames} rows ({(num_renames / N)*100} %)\")\n",
    "    \n",
    "    # Fix naming of some classes\n",
    "    cleaned_ds['class'] = cleaned_ds['class'].replace({'symptoms_lbs': 'symptoms_labs', 'symptoms_lads': 'symptoms_labs'})\n",
    "    \n",
    "    pos_invalids = cleaned_ds[~cleaned_ds['class'].isin(classes)]\n",
    "    swapped_values = pos_invalids[pos_invalids['sentence'].isin(classes)]    # Rows with swapped values\n",
    "    invalid_classes = pos_invalids[pos_invalids['class'].str.lower().isin(['', '0', '__', 'None', '[]', 'False', 'The', 'No'])]  # collect empty sentence and classes (Note that doing it here will catch the invalid swapped sentences as well)\n",
    "    ignore_classes = pos_invalids[pos_invalids['sentence'].str.contains('not a sentence')]\n",
    "    invalid_sentences = pos_invalids[pos_invalids['sentence'].str.lower().isin(['', '__', 'None', '[]', 'False', '()'])]\n",
    "\n",
    "    invalids = pos_invalids.loc[invalid_classes.index.union(invalid_sentences.index.union(ignore_classes.index))]\n",
    "    # invalids = pos_invalids.loc[invalid_classes.index.union(invalid_sentences.index)]\n",
    "    # invalids = pos_invalids[pos_invalids ['class'].isin(['', '0', '[]', 'False'])]   # Clearly invalids, temp drop to remove from our ceaned list\n",
    "    nonstd_classes = pos_invalids.drop(index=swapped_values.index.union(invalids.index))   # Get list of non-standard class rows\n",
    "    # print(ignore_classes.index[0] in list(nonstd_classes.index))\n",
    "    # print(ignore_classes.index[0] in list(invalids.index))\n",
    "    # print(nonstd_classes[nonstd_classes['sentence'].str.contains('not a sentence')])\n",
    "\n",
    "    # Get list of classes that can be classified as \"other\" with enough occurence (non-outliery)\n",
    "    # value_cnts = nonstd_classes['class'].value_counts()\n",
    "    # other_classes = value_cnts[value_cnts >= 5].index.tolist()\n",
    "    # other_class_rows = nonstd_classes[nonstd_classes['class'].isin(other_classes)]\n",
    "    # other_class_rows = other_class_rows[~other_class_rows['sentence'].str.contains('thought_process')]\n",
    "    # other_class_rows = other_class_rows[~other_class_rows['sentence'].str.contains('symptoms_labs')]\n",
    "    # other_class_indices = other_class_rows[~other_class_rows['sentence'].str.contains('diagnosis')].index  # Note we get rid of this because bad classification when it should've been \"diagnosis\", also removes \"diagnosis: \" sentences\n",
    "    # print(other_class_indices)\n",
    "    # print(value_cnts[value_cnts >= 5])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'symptoms_lbs'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'A'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'classification'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'No'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'The'])\n",
    "\n",
    "    swapped_indices = swapped_values.index\n",
    "    cleaned_ds.loc[swapped_indices, ['sentence', 'class']] = cleaned_ds.loc[swapped_indices, ['class', 'sentence']].values # swap the values in indices where it's swapped\n",
    "    # cleaned_ds.loc[other_class_indices, 'class'] = 'other'\n",
    "    # cleaned_ds['class'] = cleaned_ds['class'].apply(lambda x: 'other' if x in other_classes else x)  # relabel non-standards to 'other'\n",
    "    drop_indices = cleaned_ds[~cleaned_ds['class'].isin(classes)].index\n",
    "    # print(ignore_classes.index in list(drop_indices))\n",
    "    # print(ignore_classes.index)\n",
    "    # print(list(drop_indices))\n",
    "    \n",
    "    cleaned_ds = cleaned_ds.drop(index=drop_indices) # drop all others that aren't in our list of classes + 'other' (basically all invalids)\n",
    "\n",
    "    # Summary\n",
    "    num_reclass = cleaned_ds[cleaned_ds['class'] == 'other'].shape[0]\n",
    "    # logger.info(f\"Re-classified {len(other_classes)} classes as 'other', or {num_reclass} rows ({(num_reclass / N)*100} %)\")\n",
    "    logger.info(f'Swapped class and sentence values of {swapped_indices.shape[0]} rows ({(swapped_indices.shape[0] / N)*100} %)')\n",
    "    logger.info(f'Dropped {drop_indices.shape[0]} invalid rows ({(drop_indices.shape[0] / N)*100} %)')\n",
    "\n",
    "    # change case_id into int\n",
    "    cleaned_ds['case_id'] = cleaned_ds['case_id'].astype(int)\n",
    "    # print(cleaned_ds[cleaned_ds['sentence'].str.contains('not a sentence')])\n",
    "    \n",
    "    return cleaned_ds\n",
    "\n",
    "aug_preprocess(processed_datasets['aug_med_notes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5643b621-e1f5-48c4-b7b6-69a0c4569c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "proc_funcs = {'mimic4': mimic_preprocess, 'aug_med_notes': aug_preprocess}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dc24bb2-7506-4e5a-9115-a2951271fbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 01:58:52,814 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "2025-06-04 01:58:52,815 || INFO || MedRL-CoT Preprocess - Cleaning up aug_med_notes dataset\n",
      "2025-06-04 01:58:52,817 || INFO || MedRL-CoT Preprocess - Found 19968 rows\n",
      "2025-06-04 01:58:52,819 || INFO || MedRL-CoT Preprocess - Fixed class naming for 21 rows (0.10516826923076923 %)\n",
      "2025-06-04 01:58:52,831 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 131 rows (0.6560496794871795 %)\n",
      "2025-06-04 01:58:52,832 || INFO || MedRL-CoT Preprocess - Dropped 240 invalid rows (1.201923076923077 %)\n",
      "2025-06-04 01:58:52,834 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "2025-06-04 01:58:52,835 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "2025-06-04 01:58:52,836 || INFO || MedRL-CoT Preprocess - Cleaning up mimic4 dataset\n",
      "2025-06-04 01:58:52,838 || INFO || MedRL-CoT Preprocess - Found 29654 rows\n",
      "2025-06-04 01:58:52,841 || INFO || MedRL-CoT Preprocess - Fixed class naming for 282 rows (0.9509678289606799 %)\n",
      "2025-06-04 01:58:52,858 || INFO || MedRL-CoT Preprocess - Re-classified 18 classes as 'other', or 1073 rows (3.618398866931948 %)\n",
      "2025-06-04 01:58:52,860 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 571 rows (1.925541242328185 %)\n",
      "2025-06-04 01:58:52,860 || INFO || MedRL-CoT Preprocess - Dropped 169 invalid rows (0.5699062521076415 %)\n",
      "2025-06-04 01:58:52,863 || INFO || MedRL-CoT Preprocess - ==================================================\n"
     ]
    }
   ],
   "source": [
    "preprocessed_datasets = dict()\n",
    "for key, item in processed_datasets.items():\n",
    "    logger.info(\"=\" * 50)\n",
    "    logger.info(f\"Cleaning up {key} dataset\")\n",
    "    # processed_datasets[key] = mimic_preprocess(processed_datasets[key])\n",
    "    # mimic_preprocess(processed_datasets[key])\n",
    "    preprocessed_datasets[key] = proc_funcs[key](processed_datasets[key])\n",
    "    logger.info(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "970f8205-b8fb-4fd7-8c7a-1bb540cd4085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aug_med_notes', 'mimic4'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4410b801-5e22-47e8-8a7b-89c99c484140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "        15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
       "        41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,\n",
       "        54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n",
       "        67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
       "        80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
       "        93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
       "       106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
       "       119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
       "       132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
       "       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
       "       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
       "       171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
       "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
       "       197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "       210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
       "       223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
       "       236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
       "       249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261,\n",
       "       262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
       "       275, 276, 277, 278, 279, 280, 281, 282, 283])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_datasets['mimic4']['case_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "073ba94c-9033-41e0-977e-3663c6e95118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def join_sentence_class(group):\n",
    "#     return ' '.join(f\"{row['sentence']} <{row['class']}>\" for _, row in group.iterrows())\n",
    "    \n",
    "# # preprocessed_datasets['mimic4'].groupby('case_id').apply(join_sentence_class).reset_index(name='full_class_case').sort_values('case_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81b6f92f-91dc-48cd-bbdc-03b29b06270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases_datasets = dict()\n",
    "# for key, dataset in preprocessed_datasets.items():\n",
    "#     cases_datasets[key] = dataset.groupby('case_id').apply(join_sentence_class).reset_index(name='full_class_case').sort_values('case_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "091b4a97-8f38-4cdc-855f-74fa96912fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases_datasets['aug_med_notes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4af634f5-3278-41c4-b4f2-ad4689448f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases_datasets['aug_med_notes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2daf529-4d0a-49f9-87e9-4baa1d6e738a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preprocessed_datasets['aug_med_notes'][preprocessed_datasets['aug_med_notes']['class'] == 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a78ec6d9-3ab1-4522-9810-d475db8e3f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 01:58:53,237 || INFO || Logger - Setup for MedRL-CoT's log done. This is the beginning of the log.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated new log file logs/medrlcot145.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 01:58:53,442 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "2025-06-04 01:58:53,444 || INFO || MedRL-CoT Preprocess - Cleaning up aug_med_notes dataset\n",
      "2025-06-04 01:58:53,446 || INFO || MedRL-CoT Preprocess - Found 19968 rows\n",
      "2025-06-04 01:58:53,448 || INFO || MedRL-CoT Preprocess - Fixed class naming for 21 rows (0.10516826923076923 %)\n",
      "2025-06-04 01:58:53,471 || INFO || MedRL-CoT Preprocess - Re-classified 5 classes as 'other', or 76 rows (0.38060897435897434 %)\n",
      "2025-06-04 01:58:53,472 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 131 rows (0.6560496794871795 %)\n",
      "2025-06-04 01:58:53,473 || INFO || MedRL-CoT Preprocess - Dropped 224 invalid rows (1.1217948717948718 %)\n",
      "2025-06-04 01:58:53,474 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "2025-06-04 01:58:53,474 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "2025-06-04 01:58:53,476 || INFO || MedRL-CoT Preprocess - Cleaning up mimic4 dataset\n",
      "2025-06-04 01:58:53,478 || INFO || MedRL-CoT Preprocess - Found 29654 rows\n",
      "2025-06-04 01:58:53,480 || INFO || MedRL-CoT Preprocess - Fixed class naming for 282 rows (0.9509678289606799 %)\n",
      "2025-06-04 01:58:53,504 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 571 rows (1.925541242328185 %)\n",
      "2025-06-04 01:58:53,506 || INFO || MedRL-CoT Preprocess - Dropped 1461 invalid rows (4.9268226883388415 %)\n",
      "2025-06-04 01:58:53,506 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "/tmp/ipykernel_284586/1539373320.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cases_datasets[key] = dataset.groupby('case_id').apply(mp.xy_split_processing_sft).reset_index().sort_values('case_id')\n",
      "/tmp/ipykernel_284586/1539373320.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cases_datasets[key] = dataset.groupby('case_id').apply(mp.xy_split_processing_sft).reset_index().sort_values('case_id')\n",
      "2025-06-04 01:58:55,491 || INFO || DataManager - Loading datasets: ['aug_med_notes', 'mimic4']\n",
      "2025-06-04 01:58:55,497 || INFO || DataManager - AGBonnet/augmented-clinical-notes dataset already exists in disk. If the dataset is giving errors or you'd like a fresh install, delete the /mnt/e/UCSD/ECE285DGM/ECE285DGMProject/data/aug_med_notes/train directory.\n",
      "2025-06-04 01:58:55,498 || INFO || DataManager - Loading saved hugginface AGBonnet/augmented-clinical-notes dataset.\n",
      "2025-06-04 01:58:55,530 || INFO || DataManager - Successfully loaded AGBonnet/augmented-clinical-notes as key aug_med_notes\n",
      "2025-06-04 01:58:55,534 || INFO || DataManager - discharge.csv.gz dataset already exists in disk as huggin_face dataset. If the dataset is giving errors or you'd like a fresh install, delete the /mnt/e/UCSD/ECE285DGM/ECE285DGMProject/data/mimic4/hf directory.\n",
      "2025-06-04 01:58:55,535 || INFO || DataManager - Loading saved hugginface discharge.csv.gz dataset.\n",
      "2025-06-04 01:58:55,783 || INFO || DataManager - Successfully loaded hugging_face of discharge.csv.gz as key mimic4\n",
      "2025-06-04 01:58:55,784 || INFO || DataManager - Successfully loaded 2 datasets: ['aug_med_notes', 'mimic4']\n"
     ]
    }
   ],
   "source": [
    "def xy_split_processing_sft(group, x_func=None, y_func=None):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        if row['class'] == 'symptoms_labs' or row['class'] == 'other':\n",
    "            X.append(row)\n",
    "        else:\n",
    "            Y.append(row)\n",
    "\n",
    "    # X_case = ' '.join(f\"{row['sentence']} <{row['class']}>\" for _, row in group.iterrows()) # Input with all\n",
    "    X_case = x_func(X) if x_func else ' '.join([str(row['sentence']) for row in X])\n",
    "    Y_case = ' '.join([f\"{row['sentence']} <{row['class']}> \" for row in Y])    # Output with only thought_process and diagnosis\n",
    "    \n",
    "    X_prompt = f\"\"\"Below is a clinical case. Your task is to provide a step-by-step clinical reasoning followed by the diagnosis.\n",
    "\n",
    "    {X_case}\n",
    "    \"\"\"\n",
    "    \n",
    "    return pd.Series({'X': X_prompt, 'Y': Y_case})\n",
    "\n",
    "import medrlcot.preprocessing as mp\n",
    "preprocessed_datasets = mp.preprocess_datasets()\n",
    "\n",
    "# Combine cases into one for cases as example for SFT\n",
    "cases_datasets = dict()\n",
    "for key, dataset in preprocessed_datasets.items():\n",
    "    cases_datasets[key] = dataset.groupby('case_id').apply(mp.xy_split_processing_sft).reset_index().sort_values('case_id')\n",
    "    cases_datasets[key]['wc_x'] = cases_datasets[key]['X'].apply(lambda x: len(x.split())) \n",
    "    cases_datasets[key]['wc_y'] = cases_datasets[key]['Y'].apply(lambda x: len(x.split())) \n",
    "    cases_datasets[key] = cases_datasets[key][(cases_datasets[key]['wc_x'] <= 400) & (cases_datasets[key]['wc_y'] <= 200)].reset_index(drop=True)\n",
    "\n",
    "import os\n",
    "from medrlcot import data_manager\n",
    "import medrlcot.config.env as mce\n",
    "model_cfg_path = os.path.join(os.getcwd(), \"medrlcot/config/.env\")\n",
    "medrlcot_config = mce.MedRL_CoT(model_cfg_path)\n",
    "raw_datasets = data_manager.load_datasets(medrlcot_config.datasets, data_dir=medrlcot_config.data_dir)  # Load raw dataset (original cases) for RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d02ed4d7-95df-49bd-9597-b9e44a139564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>wc_x</th>\n",
       "      <th>wc_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: A 34 year old Persian woman, ...</td>\n",
       "      <td>159</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: She was treated with thrombol...</td>\n",
       "      <td>180</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: \\n\\n    Diagnosis: \\n</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: In the past medical history, ...</td>\n",
       "      <td>374</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: The initial workup was unreve...</td>\n",
       "      <td>248</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>915</td>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: \\n\\n    Diagnosis: \\n</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>93</td>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: The patient initially refused...</td>\n",
       "      <td>329</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>94</td>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: The working diagnosis was a c...</td>\n",
       "      <td>147</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>97</td>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: \\n\\n    Diagnosis: \\n</td>\n",
       "      <td>287</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>98</td>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: \\n\\n    Diagnosis: \\n</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    case_id                                                  X  \\\n",
       "0       100  Provide a step-by-step clinical reasoning foll...   \n",
       "1       101  Provide a step-by-step clinical reasoning foll...   \n",
       "2       102  Provide a step-by-step clinical reasoning foll...   \n",
       "3       103  Provide a step-by-step clinical reasoning foll...   \n",
       "4       104  Provide a step-by-step clinical reasoning foll...   \n",
       "..      ...                                                ...   \n",
       "512     915  Provide a step-by-step clinical reasoning foll...   \n",
       "513      93  Provide a step-by-step clinical reasoning foll...   \n",
       "514      94  Provide a step-by-step clinical reasoning foll...   \n",
       "515      97  Provide a step-by-step clinical reasoning foll...   \n",
       "516      98  Provide a step-by-step clinical reasoning foll...   \n",
       "\n",
       "                                                     Y  wc_x  wc_y  \n",
       "0    Thought Process: A 34 year old Persian woman, ...   159   168  \n",
       "1    Thought Process: She was treated with thrombol...   180   154  \n",
       "2           Thought Process: \\n\\n    Diagnosis: \\n        12     3  \n",
       "3    Thought Process: In the past medical history, ...   374   155  \n",
       "4    Thought Process: The initial workup was unreve...   248   109  \n",
       "..                                                 ...   ...   ...  \n",
       "512         Thought Process: \\n\\n    Diagnosis: \\n        87     3  \n",
       "513  Thought Process: The patient initially refused...   329    48  \n",
       "514  Thought Process: The working diagnosis was a c...   147    49  \n",
       "515         Thought Process: \\n\\n    Diagnosis: \\n       287     3  \n",
       "516         Thought Process: \\n\\n    Diagnosis: \\n       151     3  \n",
       "\n",
       "[517 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_datasets['aug_med_notes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bce3bcdf-2c5e-4959-b97b-9c617082eeed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "symptoms_labs      9977\n",
       "thought_process    5318\n",
       "diagnosis          4373\n",
       "other                76\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_datasets['aug_med_notes']['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d265d0e4-663a-49c2-b5ca-050e0567eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_datasets = dict()\n",
    "# for key, dataset in cases_datasets.items():\n",
    "#     dataset['wc_x'] = dataset['X'].apply(lambda x: len(x.split())) \n",
    "#     dataset['wc_y'] = dataset['Y'].apply(lambda x: len(x.split())) \n",
    "#     filtered_datasets[key] = dataset[(dataset['wc_x'] <= 800) & (dataset['wc_y'] <= 900)].reset_index(drop=True)\n",
    "\n",
    "# print(cases_datasets['aug_med_notes'].shape, filtered_datasets['aug_med_notes'].shape)\n",
    "# print(cases_datasets['mimic4'].shape, filtered_datasets['mimic4'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d61fa9a-274c-4cd9-b23b-975b641570ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('aug_med_notes', (175, case_id                                                  383\n",
      "X          Provide a step-by-step clinical reasoning foll...\n",
      "Y                 Thought Process: \\n\\n    Diagnosis: \\n    \n",
      "wc_x                                                     399\n",
      "wc_y                                                       3\n",
      "Name: 175, dtype: object)), 399) (('mimic4', (31, case_id                                                  196\n",
      "X          Provide a step-by-step clinical reasoning foll...\n",
      "Y          Thought Process: ___ 05:25AM   estGFR-Using th...\n",
      "wc_x                                                     399\n",
      "wc_y                                                     116\n",
      "Name: 31, dtype: object)), 399)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = (None, 0)\n",
    "next_max = (None, -1)\n",
    "num_exceed = 0\n",
    "for key, dataset in cases_datasets.items():\n",
    "    for row in dataset.iterrows():\n",
    "        cnt = ((key, row), len(row[1]['X'].split()))\n",
    "        if cnt[1] > 750:\n",
    "            num_exceed += 1\n",
    "        if cnt[1] > max_words[1]:\n",
    "            next_max = max_words\n",
    "            max_words = cnt\n",
    "        else:\n",
    "            next_max = max(cnt, next_max, key=lambda x: x[1])\n",
    "print(max_words, next_max)\n",
    "num_exceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ff63a06-c251-403a-b97f-3eec8fd85fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 01:58:56,467 || INFO || DataManager - Using train-val split: [0.75, 0.25]\n",
      "2025-06-04 01:58:56,468 || INFO || DataManager - Split-Shuffle with seed 0\n",
      "2025-06-04 01:58:56,469 || INFO || DataManager - Splitting aug_med_notes dataset.\n",
      "2025-06-04 01:58:56,471 || INFO || DataManager - Split into 387 train rows and 130 val rows\n",
      "2025-06-04 01:58:56,472 || INFO || DataManager - Splitting mimic4 dataset.\n",
      "2025-06-04 01:58:56,474 || INFO || DataManager - Split into 80 train rows and 27 val rows\n",
      "2025-06-04 01:58:56,475 || INFO || DataManager - Creating a single joint dataset of dict_keys(['aug_med_notes', 'mimic4']) dataset splits\n",
      "2025-06-04 01:58:56,476 || INFO || DataManager - Joined 467 train rows\n",
      "2025-06-04 01:58:56,477 || INFO || DataManager - Shuffling train's rows\n",
      "2025-06-04 01:58:56,479 || INFO || DataManager - Joined 157 val rows\n",
      "2025-06-04 01:58:56,480 || INFO || DataManager - Shuffling val's rows\n",
      "2025-06-04 01:58:56,481 || INFO || DataManager - Returning shuffled train-val splits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='int64')\n",
      "Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Create customd dataset obj\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\", device_map=\"auto\")\n",
    "cases_data = data_manager.MedRL_CoT_Dataset(cases_datasets, seed=0, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c93759c-e3bf-477f-9a9a-57e8cde169f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases_data['train'] = cases_data['train'].drop(cases_data['train'][cases_data['train']['Y'].str.strip() == ''].index)\n",
    "# print(cases_data['train'][cases_data['train']['X'].str.strip() == ''].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "091bc68c-8049-4a1c-bd20-71d1b4962f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: Informed written consent was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: Clinically a differential dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: continue until INR &gt;2.\\n\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: Pt admitting to walking aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: \\n\\n    Diagnosis: \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: He gave a history of having w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: Because of metastatic adenoca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: \\n\\n    Diagnosis: \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: No other investigations were ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: \\n\\n    Diagnosis: \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>467 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     X  \\\n",
       "0    Provide a step-by-step clinical reasoning foll...   \n",
       "1    Provide a step-by-step clinical reasoning foll...   \n",
       "2    Provide a step-by-step clinical reasoning foll...   \n",
       "3    Provide a step-by-step clinical reasoning foll...   \n",
       "4    Provide a step-by-step clinical reasoning foll...   \n",
       "..                                                 ...   \n",
       "462  Provide a step-by-step clinical reasoning foll...   \n",
       "463  Provide a step-by-step clinical reasoning foll...   \n",
       "464  Provide a step-by-step clinical reasoning foll...   \n",
       "465  Provide a step-by-step clinical reasoning foll...   \n",
       "466  Provide a step-by-step clinical reasoning foll...   \n",
       "\n",
       "                                                     Y  \n",
       "0    Thought Process: Informed written consent was ...  \n",
       "1    Thought Process: Clinically a differential dia...  \n",
       "2    Thought Process: continue until INR >2.\\n\\n   ...  \n",
       "3    Thought Process: Pt admitting to walking aroun...  \n",
       "4           Thought Process: \\n\\n    Diagnosis: \\n      \n",
       "..                                                 ...  \n",
       "462  Thought Process: He gave a history of having w...  \n",
       "463  Thought Process: Because of metastatic adenoca...  \n",
       "464         Thought Process: \\n\\n    Diagnosis: \\n      \n",
       "465  Thought Process: No other investigations were ...  \n",
       "466         Thought Process: \\n\\n    Diagnosis: \\n      \n",
       "\n",
       "[467 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57ba1d0d-f808-4f19-8e55-3a367692ead4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [X, Y]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_data['train'][cases_data['train']['Y'].str.strip() == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6577f860-e2bb-45e2-b632-1226e0a05543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: Informed written consent was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: Clinically a differential dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: continue until INR &gt;2.\\n\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: Pt admitting to walking aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: \\n\\n    Diagnosis: \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: He gave a history of having w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: Because of metastatic adenoca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: \\n\\n    Diagnosis: \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: No other investigations were ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Provide a step-by-step clinical reasoning foll...</td>\n",
       "      <td>Thought Process: \\n\\n    Diagnosis: \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>467 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     X  \\\n",
       "0    Provide a step-by-step clinical reasoning foll...   \n",
       "1    Provide a step-by-step clinical reasoning foll...   \n",
       "2    Provide a step-by-step clinical reasoning foll...   \n",
       "3    Provide a step-by-step clinical reasoning foll...   \n",
       "4    Provide a step-by-step clinical reasoning foll...   \n",
       "..                                                 ...   \n",
       "462  Provide a step-by-step clinical reasoning foll...   \n",
       "463  Provide a step-by-step clinical reasoning foll...   \n",
       "464  Provide a step-by-step clinical reasoning foll...   \n",
       "465  Provide a step-by-step clinical reasoning foll...   \n",
       "466  Provide a step-by-step clinical reasoning foll...   \n",
       "\n",
       "                                                     Y  \n",
       "0    Thought Process: Informed written consent was ...  \n",
       "1    Thought Process: Clinically a differential dia...  \n",
       "2    Thought Process: continue until INR >2.\\n\\n   ...  \n",
       "3    Thought Process: Pt admitting to walking aroun...  \n",
       "4           Thought Process: \\n\\n    Diagnosis: \\n      \n",
       "..                                                 ...  \n",
       "462  Thought Process: He gave a history of having w...  \n",
       "463  Thought Process: Because of metastatic adenoca...  \n",
       "464         Thought Process: \\n\\n    Diagnosis: \\n      \n",
       "465  Thought Process: No other investigations were ...  \n",
       "466         Thought Process: \\n\\n    Diagnosis: \\n      \n",
       "\n",
       "[467 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "964153c6-e86d-4aa6-960e-7eed5a27ba4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thought Process: Informed written consent was taken from the patient\\'s parent. The patient\\'s parents were made aware of nature of disease and instructed to take possible precautions.\" -> We have kept him under observation because any surgical intervention of ossified muscle might lead to further deterioration of condition as it has been experienced by patient with two previous surgeries.\" ->\\n\\n    Diagnosis: \\n    '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_data['train']['Y'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ac83011-3165-4c21-81f8-3ae069bd813a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fd9db3ca290>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_data.get_dataloader('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2524fc2-3421-43ef-a89a-4c2e3167d7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fd9db3cbdc0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_data.get_dataloader('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44c1b78f-0f78-4011-9270-b3e3ecfe14f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model  = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f88ea78e-f58c-4e93-a078-dd644f267828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    predict_with_generate=True,\n",
    "    # fp16=True,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b18df7ed-69a4-4be2-95ea-3c03fa9ff047",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0d9e217-fc17-4cdd-a578-070737acec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds): # https://www.datacamp.com/tutorial/flan-t5-tutorial\n",
    "   preds, labels = eval_preds\n",
    "\n",
    "   # decode preds and labels\n",
    "   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "   # rougeLSum expects newline after each sentence\n",
    "   decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "   decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "   result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "  \n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "420d2d61-1b6b-4328-9a70-9faa9544a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok_dataset = cases_data.get_torch_dataset('train')\n",
    "val_tok_dataset = cases_data.get_torch_dataset('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98f90dff-e9e7-4dd2-b34a-88c74f9295f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4229,    17, 10272,    10, 17656,    47, 21119, 10058,    12,  1130,\n",
       "           95,    38,  6640,    38,     8,    16,    26,  2091,    53,     3,\n",
       "         1462,   449,   138,     3,     7,  4669,   398,    36,  3641,    11,\n",
       "           42,  2509,    26,     5, 10747,     7,    15,   638, 11706,    41,\n",
       "         7171,   302,   342, 19049,    61,   164,    43,   118, 14327,    12,\n",
       "         1792,   442,    18, 31058,  6900, 11537,   257,    42,  6900, 11537,\n",
       "          257,  1341,    12,   169,    13,     3,    29,  4667,  9798,  1406,\n",
       "        11208,     5,  2678, 14175,    15,     3,    99,  6044, 22429,    42,\n",
       "        28582,  1344,     7,     5,   638, 11706,    19,     3,     9, 22429,\n",
       "           18, 12369,    35,    49,     6,  4486,     3,     9,    50,   226,\n",
       "         1528,     5,    37,  1868,    31,     7,   892,    13,  6676, 13177,\n",
       "           11,  6676, 19437, 11658,    47,  1702,     5,  5267,  6715,     7,\n",
       "          159,    10,     3,     1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = val_tok_dataset[80]\n",
    "t['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01c5e930-b3bb-4530-8824-0b2b2df99d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Provide a step-by-step clinical reasoning followed by the diagnosis: History of Present Illness: This is a ___ year old female who presents with left flank pain x4 days. Patient has short term memory loss and is a poor historian, history obtained with assistance of patient's mother. Pain in the left flank started approximately 4 days ago associated with dysuria and nausea. Unsure if she has had fever, chills but currently denies f/c/cp/sob. Never had a stone before. Last PO last night. Social History: Family History: Physical Exam: GEN: NAD, resting comfortably, AAO HEENT: NCAT, EOMI, anicteric sclera PULM: nonlabored breathing, normal chest rise ABD: soft, NT, ND, no rebound/guarding EXT: WWP Pertinent Results: 04:50PM BLOOD WBC-9.1 RBC-3.96 Hgb-12.1 Hct-37.0 MCV-93 MCH-30.6 MCHC-32.7 RDW-13.4 RDWSD-45.9 Plt ___ 06:05AM BLOOD Glucose-102* UreaN-19 Creat-1.7* Na-142 K-3.8 Cl-105 HCO3-20* AnGap-17 Medications on Admission: The Preadmission Medication list may be inaccurate and requires further investigation. 1. Acetaminophen 325-650 mg PO Q6H:PRN pain, fever 2. Atorvastatin 40 mg PO DAILY 3. Docusate Sodium 100 mg PO BID 4. Gabapentin 600 mg PO BID 5. Multivitamins 1 TAB PO DAILY 6. Omeprazole 20 mg PO DAILY 7. Topiramate (Topamax) 100 mg PO BID 8. Warfarin 2.5 mg PO 3X/WEEK (___) 9. Warfarin 5 mg PO 4X/WEEK (___) 10. LeVETiracetam 500 mg PO BID 11. LeVETiracetam 250 mg PO QPM 12. Lorazepam 0.5-1 mg PO AS NEEDED FOR SEIZURE 13. Calcium Carbonate 1250 mg PO D</s>\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(t['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36e8c2a8-ff7a-45c2-87f9-3b1a93b12fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought Process: Patient was explicitly advised to follow up as directed as the indwelling ureteral stent must be removed and or exchanged. False Colace (docusate sodium) may have been prescribed to avoid post-surgical constipation or constipation related to use of narcotic pain medications. Discontinue if loose stool or diarrhea develops. Colace is a stool-softener, NOT a laxative. The patient's history of hypertension and hyperlipidemia was considered. Diagnosis: \n"
     ]
    }
   ],
   "source": [
    "label_ids = t['labels']\n",
    "# Remove masked (-100) values\n",
    "cleaned_labels = [token_id for token_id in label_ids if token_id != -100]\n",
    "decoded = tokenizer.decode(cleaned_labels, skip_special_tokens=True)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83f755d0-2006-41a9-af94-b33df58d7308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Acetaminophen 325-650 mg PO Q6H:PRN pain, fever 2. Atorvastatin 325-650 mg PO Q6H:PRN pain, fever 3. Atorvastatin 4 mg PO Q6H:PRN pain, fever 4. Gabapentin 5 mg PO BID 5. Multivitamins 1 TAB PO DAILY 6. Omeprazole 20 mg PO QPM 7. Topiramate (Topamax) 100 mg PO BID 8. Warfarin 2.5 mg PO 3X/WEEK (_____) 9. Warfarin 5 mg PO 4X/WEEK (________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = val_tok_dataset[80]\n",
    "input_ids = inputs[\"input_ids\"].unsqueeze(0).to(model.device)\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(0).to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask, max_new_tokens=200)\n",
    "\n",
    "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70336c3a-23e2-4790-9b71-5ed21253f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = val_tok_dataset[0]\n",
    "# print(tokenizer.decode(sample[\"input_ids\"]))|\n",
    "# print(tokenizer.decode(sample['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39ca4695-8d06-4388-bfa2-6e673f19c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_tok_dataset,\n",
    "    eval_dataset=val_tok_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c91efb80-a238-4605-8d69-e00f2ee73a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input Text ==\n",
      "Provide a step-by-step clinical reasoning followed by the diagnosis: A 5-year-old male child came to the department of oral and maxillofacial surgery with a complaint of difficulty in opening the mouth for the past 2 years. The birth history was normal. No other member of the family was similarly affected. His mouth opening was normal until he met with a trauma with wooden thorn on the left cheek region. Thorn was removed by a surgeon immediately, but the patient had progressively reduced mouth opening since then. Computed tomography scan showed a radiodense mass extending in front of the anterior border of the ramus of the mandible, suggestive of ossified masseter muscle []. Magnetic resonance imaging revealed evidence of a large elongated T1–T2 intermediate signal intensity lesion with mild surrounding edema in the substance of left masseter muscle, abutting the ramus of left mandible likely to represent heterotopic bone formation (at the expected location of previous surgery for thorn extraction) []. The patient's father said that the patient had a history of pain and swelling in the left thigh region and limited movement of the left leg 3 years back when he was only 2 years old. His front and lateral leg radiograph showed bony growth over femur. Subsequent three X-rays of the leg were taken at an interval of 1 month which showed progressive increase in ossification [Figure -]. However, unfortunately, he was misdiagnosed for any bony growth in his left thigh and advised for surgical removal of the same. He got operated for the left leg in 2016; however, after operation, he had total immobility of the left leg. Postoperative radiograph of the leg showed cord-like ossification of the muscles and soft tissue of the left leg giving pattern of branching tree []. Local examination of the face showed that the mouth opening was reduced to nil []. A full-body examination revealed ossifications and a scar mark of previously operated site in the left leg regions []. In addition, microdactyly of the great toe on both the feet was seen []. Thought Process: Diagnosis: \n",
      "\n",
      "== Label Text ==\n",
      "Thought Process: Informed written consent was taken from the patient's parent. The patient's parents were made aware of nature of disease and instructed to take possible precautions.\" -> We have kept him under observation because any surgical intervention of ossified muscle might lead to further deterioration of condition as it has been experienced by patient with two previous surgeries.\" -> Diagnosis: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.3646023273468018\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "sample = train_tok_dataset[0]\n",
    "batch = {k: v.unsqueeze(0).to(model.device) for k, v in sample.items()}\n",
    "with torch.no_grad():\n",
    "    output = model(**batch)\n",
    "print(\"Loss:\", output.loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c340c6d3-9b7b-442a-b23b-082ef8449433",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6a9653c-0e0c-4e1b-90f6-f7a1d078478d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Pikasannnnn/.pyenv/versions/anaconda3-2024.06-1/envs/medrlcot/lib/python3.10/site-packages/transformers/data/data_collator.py:741: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1401' max='1401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1401/1401 04:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.970100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.692600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input Text ==\n",
      "Provide a step-by-step clinical reasoning followed by the diagnosis: A 5-year-old male child came to the department of oral and maxillofacial surgery with a complaint of difficulty in opening the mouth for the past 2 years. The birth history was normal. No other member of the family was similarly affected. His mouth opening was normal until he met with a trauma with wooden thorn on the left cheek region. Thorn was removed by a surgeon immediately, but the patient had progressively reduced mouth opening since then. Computed tomography scan showed a radiodense mass extending in front of the anterior border of the ramus of the mandible, suggestive of ossified masseter muscle []. Magnetic resonance imaging revealed evidence of a large elongated T1–T2 intermediate signal intensity lesion with mild surrounding edema in the substance of left masseter muscle, abutting the ramus of left mandible likely to represent heterotopic bone formation (at the expected location of previous surgery for thorn extraction) []. The patient's father said that the patient had a history of pain and swelling in the left thigh region and limited movement of the left leg 3 years back when he was only 2 years old. His front and lateral leg radiograph showed bony growth over femur. Subsequent three X-rays of the leg were taken at an interval of 1 month which showed progressive increase in ossification [Figure -]. However, unfortunately, he was misdiagnosed for any bony growth in his left thigh and advised for surgical removal of the same. He got operated for the left leg in 2016; however, after operation, he had total immobility of the left leg. Postoperative radiograph of the leg showed cord-like ossification of the muscles and soft tissue of the left leg giving pattern of branching tree []. Local examination of the face showed that the mouth opening was reduced to nil []. A full-body examination revealed ossifications and a scar mark of previously operated site in the left leg regions []. In addition, microdactyly of the great toe on both the feet was seen []. Thought Process: Diagnosis: \n",
      "\n",
      "== Label Text ==\n",
      "Thought Process: Informed written consent was taken from the patient's parent. The patient's parents were made aware of nature of disease and instructed to take possible precautions.\" -> We have kept him under observation because any surgical intervention of ossified muscle might lead to further deterioration of condition as it has been experienced by patient with two previous surgeries.\" -> Diagnosis: \n",
      "== Input Text ==\n",
      "Provide a step-by-step clinical reasoning followed by the diagnosis: A 5-year-old male child came to the department of oral and maxillofacial surgery with a complaint of difficulty in opening the mouth for the past 2 years. The birth history was normal. No other member of the family was similarly affected. His mouth opening was normal until he met with a trauma with wooden thorn on the left cheek region. Thorn was removed by a surgeon immediately, but the patient had progressively reduced mouth opening since then. Computed tomography scan showed a radiodense mass extending in front of the anterior border of the ramus of the mandible, suggestive of ossified masseter muscle []. Magnetic resonance imaging revealed evidence of a large elongated T1–T2 intermediate signal intensity lesion with mild surrounding edema in the substance of left masseter muscle, abutting the ramus of left mandible likely to represent heterotopic bone formation (at the expected location of previous surgery for thorn extraction) []. The patient's father said that the patient had a history of pain and swelling in the left thigh region and limited movement of the left leg 3 years back when he was only 2 years old. His front and lateral leg radiograph showed bony growth over femur. Subsequent three X-rays of the leg were taken at an interval of 1 month which showed progressive increase in ossification [Figure -]. However, unfortunately, he was misdiagnosed for any bony growth in his left thigh and advised for surgical removal of the same. He got operated for the left leg in 2016; however, after operation, he had total immobility of the left leg. Postoperative radiograph of the leg showed cord-like ossification of the muscles and soft tissue of the left leg giving pattern of branching tree []. Local examination of the face showed that the mouth opening was reduced to nil []. A full-body examination revealed ossifications and a scar mark of previously operated site in the left leg regions []. In addition, microdactyly of the great toe on both the feet was seen []. Thought Process: Diagnosis: \n",
      "\n",
      "== Label Text ==\n",
      "Thought Process: Informed written consent was taken from the patient's parent. The patient's parents were made aware of nature of disease and instructed to take possible precautions.\" -> We have kept him under observation because any surgical intervention of ossified muscle might lead to further deterioration of condition as it has been experienced by patient with two previous surgeries.\" -> Diagnosis: \n",
      "== Input Text ==\n",
      "Provide a step-by-step clinical reasoning followed by the diagnosis: A 5-year-old male child came to the department of oral and maxillofacial surgery with a complaint of difficulty in opening the mouth for the past 2 years. The birth history was normal. No other member of the family was similarly affected. His mouth opening was normal until he met with a trauma with wooden thorn on the left cheek region. Thorn was removed by a surgeon immediately, but the patient had progressively reduced mouth opening since then. Computed tomography scan showed a radiodense mass extending in front of the anterior border of the ramus of the mandible, suggestive of ossified masseter muscle []. Magnetic resonance imaging revealed evidence of a large elongated T1–T2 intermediate signal intensity lesion with mild surrounding edema in the substance of left masseter muscle, abutting the ramus of left mandible likely to represent heterotopic bone formation (at the expected location of previous surgery for thorn extraction) []. The patient's father said that the patient had a history of pain and swelling in the left thigh region and limited movement of the left leg 3 years back when he was only 2 years old. His front and lateral leg radiograph showed bony growth over femur. Subsequent three X-rays of the leg were taken at an interval of 1 month which showed progressive increase in ossification [Figure -]. However, unfortunately, he was misdiagnosed for any bony growth in his left thigh and advised for surgical removal of the same. He got operated for the left leg in 2016; however, after operation, he had total immobility of the left leg. Postoperative radiograph of the leg showed cord-like ossification of the muscles and soft tissue of the left leg giving pattern of branching tree []. Local examination of the face showed that the mouth opening was reduced to nil []. A full-body examination revealed ossifications and a scar mark of previously operated site in the left leg regions []. In addition, microdactyly of the great toe on both the feet was seen []. Thought Process: Diagnosis: \n",
      "\n",
      "== Label Text ==\n",
      "Thought Process: Informed written consent was taken from the patient's parent. The patient's parents were made aware of nature of disease and instructed to take possible precautions.\" -> We have kept him under observation because any surgical intervention of ossified muscle might lead to further deterioration of condition as it has been experienced by patient with two previous surgeries.\" -> Diagnosis: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1401, training_loss=2.7813816547053443, metrics={'train_runtime': 276.8587, 'train_samples_per_second': 5.06, 'train_steps_per_second': 5.06, 'total_flos': 173532779882496.0, 'train_loss': 2.7813816547053443, 'epoch': 3.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0080a57a-bc1c-493d-a64e-3a6af5dc7d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_case = cases_data['val'].iloc[-1]\n",
    "\n",
    "# val_input = example_case[\"X\"]\n",
    "# val_target = example_case[\"Y\"]\n",
    "# val_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8cca948-a336-4a7e-9603-a02711df3886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 7740,     3,     9,  1147,    18,   969,    18,  7910,  3739, 20893,\n",
       "          2348,    57,     8,  8209,    10,  5528,    13, 18795,    27,   195,\n",
       "           655,    10,   100,    19,     3,     9,     3,   834,   834,   834,\n",
       "           215,   625,  3955,   113,  6621,    28,   646, 24397,  1406,     3,\n",
       "           226,   591,   477,     5, 17656,    65,   710,  1657,  2594,  1453,\n",
       "            11,    19,     3,     9,  2714, 18637,     6,   892,  5105,    28,\n",
       "          2927,    13,  1868,    31,     7,  2039,     5, 19043,    16,     8,\n",
       "           646, 24397,   708,  3241,   314,   477,   977,  1968,    28, 16633,\n",
       "           459,     9,    11, 25808,     5,   597,  4334,     3,    99,   255,\n",
       "            65,   141, 17055,     6, 10191,     7,    68,  1083,   177,   725,\n",
       "             3,    89,    87,    75,    87,    75,   102,    87,     7,    32,\n",
       "           115,     5,  8400,   141,     3,     9,  3372,   274,     5,  2506,\n",
       "          9915,   336,   706,     5,  2730,  5528,    10,  3712,  5528,    10,\n",
       "         15576,  9723,    10,     3, 18464,    10,   445,  6762,     6,   880,\n",
       "            53, 17540,     6,    71, 17249,     3,  6021,  6431,    10,   445,\n",
       "         18911,     6,     3, 13113,  7075,     6,    46,   447,   449,   447,\n",
       "             3,     7,    75,  1171,     9,     3, 10744, 11160,    10,   529,\n",
       "          9456,    15,    26, 10882,     6,  1389,  5738,  3098,    71, 14594,\n",
       "            10,  1835,     6,     3,  7359,     6,     3, 10604,     6,   150,\n",
       "         20756,    87, 11010,    53,   262,     4,   382,    10, 18548,   345,\n",
       "          1915,    17,    77,   295, 12772,    10, 11484,    10,  1752,  6218,\n",
       "           272,  5017,  7039,   549,  7645,  7141,     5,   536,   391,  7645,\n",
       "          3486,     5,  4314,   454,   122,   115,  2292, 14489,   454,    75,\n",
       "            17,  3486, 26346,   283, 20410,    18,  4271,   283,  8360,  3486,\n",
       "         22787,     3,  3698,  8095,  3486, 21280,   391, 20293,  2292, 23204,\n",
       "           391, 20293,  7331,    18,  2128,     5,  1298,  7337,    17,     3,\n",
       "           834,   834,   834, 13574,    10,  3076,  4815,   272,  5017,  7039,\n",
       "             3, 21597,   509,     7,    15,    18, 14388,  1935,   412,   864,\n",
       "           567,  4481,  5895,   144,    18, 18596,  1935,  1823,    18, 24978,\n",
       "           480,    18, 26195,  4779,    18, 12869,   454,  5911,   519,  7988,\n",
       "          1935,   389,   517,     9,   102, 10794,     3, 15789,  1628,    30,\n",
       "         22100,    10,    37,   276,  5236,  5451,  1212, 17530,   570,   164,\n",
       "            36, 27801,    11,  2311,   856,  4962,     5,  1300, 16475,    17,\n",
       "             9,  1109, 10775,    35,   220,  1828,    18, 15348,  5453,  9915,\n",
       "          1593,   948,   566,    10,  5554,   567,  1406,     6, 17055,  1682,\n",
       "           486,   127,   900,  8547,    77,  1283,  5453,  9915,   309, 22862,\n",
       "           476,  1877, 17268,   302,   342,     3, 28637,   910,  5453,  9915,\n",
       "           272,  4309,  2853, 15894,     9,   102,   295,    77,  7366,  5453,\n",
       "          9915,   272,  4309,  3594,  4908, 12411,  1109,     7,   209,   332,\n",
       "          5359,  9915,   309, 22862,   476,  4357, 13285,    15,  5319, 12423,\n",
       "            15,   460,  5453,  9915,   309, 22862,   476,  4306,   304,  2388,\n",
       "             9,  5058,    41, 22481,     9,  9128,    61,   910,  5453,  9915,\n",
       "           272,  4309,  4848,  1602,  5544,    77, 10603,  5453,  9915,   220,\n",
       "             4,    87,   518,  5080,   439,    41,   834,   834,   834,    61,\n",
       "          5835,  1602,  5544,    77,   305,  5453,  9915,   314,     4,    87,\n",
       "           518,  5080,   439,    41,   834,   834,   834,    61,  5477,   312,\n",
       "          8575,   382,    23, 12614,    17,   265,  2899,  5453,  9915,   272,\n",
       "          4309,  7806,   312,  8575,   382,    23, 12614,    17,   265,  5986,\n",
       "          5453,  9915,  1593,  6218,  8013,  8410,     9,   776,   102,   265,\n",
       "             3, 12100,  2292,  5453,  9915,  6157, 28969,  2326,  5652,  5985,\n",
       "         20091, 18290,  8808, 30655, 14335,   342,   586,  1752,  5453,  9915,\n",
       "           309,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'labels': tensor([ 4229,    17, 10272,    10, 17656,    47, 21119, 10058,    12,  1130,\n",
       "            95,    38,  6640,    38,     8,    16,    26,  2091,    53,     3,\n",
       "          1462,   449,   138,     3,     7,  4669,   398,    36,  3641,    11,\n",
       "            42,  2509,    26,     5, 10747,     7,    15,   638, 11706,    41,\n",
       "          7171,   302,   342, 19049,    61,   164,    43,   118, 14327,    12,\n",
       "          1792,   442,    18, 31058,  6900, 11537,   257,    42,  6900, 11537,\n",
       "           257,  1341,    12,   169,    13,     3,    29,  4667,  9798,  1406,\n",
       "         11208,     5,  2678, 14175,    15,     3,    99,  6044, 22429,    42,\n",
       "         28582,  1344,     7,     5,   638, 11706,    19,     3,     9, 22429,\n",
       "            18, 12369,    35,    49,     6,  4486,     3,     9,    50,   226,\n",
       "          1528,     5,    37,  1868,    31,     7,   892,    13,  6676, 13177,\n",
       "            11,  6676, 19437, 11658,    47,  1702,     5,  5267,  6715,     7,\n",
       "           159,    10,     3,     1])}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_tok_dataset[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6fa52eb-3f42-4676-847d-601ce82ffdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.decode(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69341638-c971-492b-920a-fe8ab793d9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input Text ==\n",
      "Provide a step-by-step clinical reasoning followed by the diagnosis: A 5-year-old male child came to the department of oral and maxillofacial surgery with a complaint of difficulty in opening the mouth for the past 2 years. The birth history was normal. No other member of the family was similarly affected. His mouth opening was normal until he met with a trauma with wooden thorn on the left cheek region. Thorn was removed by a surgeon immediately, but the patient had progressively reduced mouth opening since then. Computed tomography scan showed a radiodense mass extending in front of the anterior border of the ramus of the mandible, suggestive of ossified masseter muscle []. Magnetic resonance imaging revealed evidence of a large elongated T1–T2 intermediate signal intensity lesion with mild surrounding edema in the substance of left masseter muscle, abutting the ramus of left mandible likely to represent heterotopic bone formation (at the expected location of previous surgery for thorn extraction) []. The patient's father said that the patient had a history of pain and swelling in the left thigh region and limited movement of the left leg 3 years back when he was only 2 years old. His front and lateral leg radiograph showed bony growth over femur. Subsequent three X-rays of the leg were taken at an interval of 1 month which showed progressive increase in ossification [Figure -]. However, unfortunately, he was misdiagnosed for any bony growth in his left thigh and advised for surgical removal of the same. He got operated for the left leg in 2016; however, after operation, he had total immobility of the left leg. Postoperative radiograph of the leg showed cord-like ossification of the muscles and soft tissue of the left leg giving pattern of branching tree []. Local examination of the face showed that the mouth opening was reduced to nil []. A full-body examination revealed ossifications and a scar mark of previously operated site in the left leg regions []. In addition, microdactyly of the great toe on both the feet was seen []. Thought Process: Diagnosis: \n",
      "\n",
      "== Label Text ==\n",
      "Thought Process: Informed written consent was taken from the patient's parent. The patient's parents were made aware of nature of disease and instructed to take possible precautions.\" -> We have kept him under observation because any surgical intervention of ossified muscle might lead to further deterioration of condition as it has been experienced by patient with two previous surgeries.\" -> Diagnosis: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Provide a step-by-step clinical reasoning followed by the diagnosis: A 5-year-old male child came to the department of oral and maxillofacial surgery with a complaint of difficulty in opening the mouth for the past 2 years. The birth history was normal. No other member of the family was similarly affected. His mouth opening was normal until he met with a trauma with wooden thorn on the left cheek region. Thorn was removed by a surgeon immediately, but the patient had progressively reduced mouth opening since then. Computed tomography scan showed a radiodense mass extending in front of the anterior border of the ramus of the mandible, suggestive of ossified masseter muscle []. Magnetic resonance imaging revealed evidence of a large elongated T1–T2 intermediate signal intensity lesion with mild surrounding edema in the substance of left masseter muscle, abutting the ramus of left mandible likely to represent heterotopic bone formation (at the expected location of previous surgery for thorn extraction) []. The patient's father said that the patient had a history of pain and swelling in the left thigh region and limited movement of the left leg 3 years back when he was only 2 years old. His front and lateral leg radiograph showed bony growth over femur. Subsequent three X-rays of the leg were taken at an interval of 1 month which showed progressive increase in ossification [Figure -]. However, unfortunately, he was misdiagnosed for any bony growth in his left thigh and advised for surgical removal of the same. He got operated for the left leg in 2016; however, after operation, he had total immobility of the left leg. Postoperative radiograph of the leg showed cord-like ossification of the muscles and soft tissue of the left leg giving pattern of branching tree []. Local examination of the face showed that the mouth opening was reduced to nil []. A full-body examination revealed ossifications and a scar mark of previously operated site in the left leg regions []. In addition, microdactyly of the great toe on both the feet was seen []. Thought Process: Diagnosis: </s>\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_tok_dataset[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3d0a0ce-3cf2-420f-b2f8-e6bf737d7e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Pikasannnnn/.pyenv/versions/anaconda3-2024.06-1/envs/medrlcot/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Though),\n"
     ]
    }
   ],
   "source": [
    "inputs = train_tok_dataset[10]\n",
    "input_ids = inputs[\"input_ids\"].unsqueeze(0).to(model.device)\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(0).to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask, max_new_tokens=256)\n",
    "\n",
    "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fa1d4bb-c6d9-4a71-a35a-eaa11746b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_case = \"\"\"\n",
    "# John Doe is a 40-year-old male who was involved in a motor vehicle accident. \n",
    "# He was a restrained passenger who was rear-ended by another car going approximately 45 mph. \n",
    "# He has no medical history and takes no medications at home. \n",
    "# He has no allergies. His primary physician is Dr. Johnson. He has been awake, alert, and oriented with a Glasgow Coma Score of 15 since arrival. \n",
    "# He is moving all extremities and has good strength bilaterally. \n",
    "# His chief complaint is neck pain, rated a 5 out of 10, and he remains in cervical-spine precautions until the trauma team clears him. \n",
    "# He is to be kept NPO until cleared by the trauma team as well. CT scans have been completed of the head, cervical spine, chest, abdomen, and pelvis. \n",
    "# We are pending reports from radiology. Last vital signs, 15 minutes ago, were temperature 36.6, pulse 80, respiratory rate 14, and blood pressure 120/80. Lung sounds are clear.\n",
    "# The abdomen is soft and non-tender. The patient has two largebore IVs. The Right AC 18 gauge with 1 liter Lactated Ringers at TKO. \n",
    "# The left AC has been saline locked. The patient received fentanyl 50 mcg slow IVP, and stated relief, with pain now 1 out of 10. \n",
    "# The family is at the bedside, and the patient remains in good spirits.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10379d3d-3348-4258-aa46-4c7113516f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
