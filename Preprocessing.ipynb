{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89d5679-991e-4f17-bcdf-a39beef3ef0e",
   "metadata": {},
   "source": [
    "### Preprocessing for Mimic4 Dataset\n",
    "\n",
    "**Note that the AUG dataset is incomplete, so we skip it here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52ad5779-a5ac-4867-9b7f-fc3023047b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e50ca3-9850-42d7-b71f-8390c9a90dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medrlcot.config.env import MedRL_CoT\n",
    "from medrlcot import data_manager\n",
    "from medrlcot.medrlcot_logger import setup_logger\n",
    "from dotenv import load_dotenv\n",
    "from datasets import Features, Value\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets as hf_datasets\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)  \n",
    "# pd.set_option('display.width', 0)    \n",
    "# pd.set_option('display.max_rows', None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a0e936-71fc-48ac-b099-6f3050346a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 02:44:17,528 || INFO || Logger - Setup for MedRL-CoT's log done. This is the beginning of the log.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated new log file logs/medrlcot092.log\n"
     ]
    }
   ],
   "source": [
    "model_cfg_path = os.path.join(os.getcwd(), \"medrlcot/config/.env\")\n",
    "medrlcot_config = MedRL_CoT(model_cfg_path)\n",
    "\n",
    "setup_logger()\n",
    "logger = logging.getLogger(\"MedRL-CoT Preprocess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c6e504-937a-4abe-9c61-aa5c59490b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aug_med_notes', 'mimic4'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processed_dirs = [os.path.join(os.getcwd(), medrlcot_config.data_dir, ds, 'processed') for ds in medrlcot_config.datasets]\n",
    "processed_dirs = {ds: os.path.join(os.getcwd(), medrlcot_config.data_dir, ds, 'processed') for ds in medrlcot_config.datasets}\n",
    "processed_dirs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "499d4653-c605-406c-ad24-a1580c7e1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(['symptoms_labs', 'thought_process', 'diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7871d1-58d9-4dd2-86ed-e4b44df82554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labeled(arrow_dir):\n",
    "    arrows = [os.path.join(arrow_dir, f) for f in os.listdir(arrow_dir) if f.endswith(\".arrow\")]\n",
    "    processed_dataset = hf_datasets.concatenate_datasets([hf_datasets.Dataset.from_file(arrow) for arrow in arrows]).to_dict()\n",
    "\n",
    "    return processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7b55fa0-aabe-4327-ac1f-b59a26e9d07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aug_med_notes', 'mimic4'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_datasets = {key: pd.DataFrame(load_labeled(processed_dir)) for key, processed_dir in processed_dirs.items()}\n",
    "processed_datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a03decef-49ea-4bfe-98be-b5765f7876e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 03:22:10,897 || INFO || Logger - Setup for MedRL-CoT's log done. This is the beginning of the log.\n",
      "2025-06-03 03:22:10,902 || INFO || MedRL-CoT Preprocess - Found 29654 rows\n",
      "2025-06-03 03:22:10,905 || INFO || MedRL-CoT Preprocess - Fixed class naming for 282 rows (0.9509678289606799 %)\n",
      "2025-06-03 03:22:10,924 || INFO || MedRL-CoT Preprocess - Re-classified 18 classes as 'other', or 1073 rows (3.618398866931948 %)\n",
      "2025-06-03 03:22:10,926 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 571 rows (1.925541242328185 %)\n",
      "2025-06-03 03:22:10,927 || INFO || MedRL-CoT Preprocess - Dropped 169 invalid rows (0.5699062521076415 %)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated new log file logs/medrlcot095.log\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "      <th>case_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>History of Present Illness:</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pt reports self-discontinuing lasix and spirno...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She does not follow Na-restricted diets.</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the past week, she notes that she has been ...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>She denies ___ edema, or SOB, or orthopnea.</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29649</th>\n",
       "      <td>Please call cardiac surgery office with any qu...</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29650</th>\n",
       "      <td>Patient presented with a chief complaint of ch...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29651</th>\n",
       "      <td>The ECG showed no signs of ischemia.</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29652</th>\n",
       "      <td>The patient's history of hypertension and hype...</td>\n",
       "      <td>thought_process</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29653</th>\n",
       "      <td>A diagnosis of stable angina was made.</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29485 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence            class  \\\n",
       "0                            History of Present Illness:    symptoms_labs   \n",
       "1      Pt reports self-discontinuing lasix and spirno...    symptoms_labs   \n",
       "2               She does not follow Na-restricted diets.    symptoms_labs   \n",
       "3      In the past week, she notes that she has been ...    symptoms_labs   \n",
       "4            She denies ___ edema, or SOB, or orthopnea.    symptoms_labs   \n",
       "...                                                  ...              ...   \n",
       "29649  Please call cardiac surgery office with any qu...        diagnosis   \n",
       "29650  Patient presented with a chief complaint of ch...    symptoms_labs   \n",
       "29651               The ECG showed no signs of ischemia.    symptoms_labs   \n",
       "29652  The patient's history of hypertension and hype...  thought_process   \n",
       "29653             A diagnosis of stable angina was made.        diagnosis   \n",
       "\n",
       "       case_id  \n",
       "0           -1  \n",
       "1           -1  \n",
       "2           -1  \n",
       "3           -1  \n",
       "4           -1  \n",
       "...        ...  \n",
       "29649      283  \n",
       "29650      283  \n",
       "29651      283  \n",
       "29652      283  \n",
       "29653      283  \n",
       "\n",
       "[29485 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mimic_preprocess(dataset):\n",
    "    cleaned_ds = dataset.copy()\n",
    "\n",
    "    # For loggin purposes\n",
    "    N = cleaned_ds.shape[0]\n",
    "    logger.info(f\"Found {N} rows\")\n",
    "    num_renames = cleaned_ds[cleaned_ds['class'].isin(['symptoms_lbs', 'symptoms_lads'])].shape[0]\n",
    "    logger.info(f\"Fixed class naming for {num_renames} rows ({(num_renames / N)*100} %)\")\n",
    "    \n",
    "    # Fix naming of some classes\n",
    "    cleaned_ds['class'] = cleaned_ds['class'].replace({'symptoms_lbs': 'symptoms_labs', 'symptoms_lads': 'symptoms_labs'})\n",
    "    \n",
    "    pos_invalids = cleaned_ds[~cleaned_ds['class'].isin(classes)]\n",
    "    swapped_values = pos_invalids[pos_invalids['sentence'].str.lower().isin(classes)]    # Rows with swapped values\n",
    "    \n",
    "    # Clearly invalids, temp drop to remove from our ceaned list\n",
    "    invalid_classes = pos_invalids[pos_invalids['class'].str.lower().isin(['', '0', '__', 'None'])]  # collect empty sentence and classes (Note that doing it here will catch the invalid swapped sentences as well)\n",
    "    invalid_sentences = pos_invalids[pos_invalids['sentence'].str.lower().isin(['', '__', 'None'])]\n",
    "    invalids = pos_invalids.loc[invalid_classes.index.union(invalid_sentences.index)]\n",
    "    nonstd_classes = pos_invalids.drop(index=swapped_values.index.union(invalids.index))   # Get list of non-standard classes\n",
    "\n",
    "    # Get list of classes that can be classified as \"other\" with enough occurence (non-outliery)\n",
    "    # value_cnts = nonstd_classes['class'].value_counts()\n",
    "    # other_classes = value_cnts[value_cnts >= 5].index.tolist()\n",
    "    value_cnts = nonstd_classes['class'].value_counts()\n",
    "    other_classes = value_cnts[value_cnts >= 5].index.tolist()\n",
    "    other_class_indices = nonstd_classes[nonstd_classes['class'].isin(other_classes)].index\n",
    "    # print(value_cnts[value_cnts >= 5])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'past_surgical_history'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'followup_instructions'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'demographic_data'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'past_surgical_history'])\n",
    "    \n",
    "    # Clean the dataset\n",
    "    swapped_indices = swapped_values.index\n",
    "    cleaned_ds.loc[swapped_indices, ['sentence', 'class']] = cleaned_ds.loc[swapped_indices, ['class', 'sentence']].values # swap the values in indices where it's swapped\n",
    "    cleaned_ds.loc[other_class_indices, 'class'] = 'other'\n",
    "    # cleaned_ds['class'] = cleaned_ds['class'].apply(lambda x: 'other' if x in other_classes else x)  # relabel non-standards to 'other'\n",
    "    drop_indices = cleaned_ds[~cleaned_ds['class'].isin(np.append(classes, 'other'))].index\n",
    "    cleaned_ds = cleaned_ds.drop(index=drop_indices) # drop all others that aren't in our list of classes + 'other'  (basically all invalids)\n",
    "\n",
    "    # Summary\n",
    "    num_reclass = cleaned_ds[cleaned_ds['class'] == 'other'].shape[0]\n",
    "    logger.info(f\"Re-classified {len(other_classes)} classes as 'other', or {num_reclass} rows ({(num_reclass / N)*100} %)\")\n",
    "    logger.info(f'Swapped class and sentence values of {swapped_indices.shape[0]} rows ({(swapped_indices.shape[0] / N)*100} %)')\n",
    "    logger.info(f'Dropped {drop_indices.shape[0]} invalid rows ({(drop_indices.shape[0] / N)*100} %)')\n",
    "\n",
    "    # change case_id into int\n",
    "    cleaned_ds['case_id'] = cleaned_ds['case_id'].astype(int)\n",
    "\n",
    "    return cleaned_ds\n",
    "\n",
    "mimic_preprocess(processed_datasets['mimic4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f58e2d2b-b3ac-4d4a-86c2-4cecc94f1fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 03:22:11,032 || INFO || MedRL-CoT Preprocess - Found 19968 rows\n",
      "2025-06-03 03:22:11,035 || INFO || MedRL-CoT Preprocess - Fixed class naming for 21 rows (0.10516826923076923 %)\n",
      "2025-06-03 03:22:11,048 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 131 rows (0.6560496794871795 %)\n",
      "2025-06-03 03:22:11,049 || INFO || MedRL-CoT Preprocess - Dropped 240 invalid rows (1.201923076923077 %)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "      <th>case_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A sixteen year-old girl, presented to our Outp...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She was not able to maintain an erect posture ...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She would keep her head turned to the right an...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There was a sideways bending of the back in th...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To counter the abnormal positioning of the bac...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19963</th>\n",
       "      <td>No significant muscle atrophy was present, and...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19964</th>\n",
       "      <td>The physical examination showed that both of h...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19965</th>\n",
       "      <td>Both knees were very soft and could touch the ...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19966</th>\n",
       "      <td>Upon palpation, the continuity of the quadrice...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19967</th>\n",
       "      <td>In addition, the patient could not complete kn...</td>\n",
       "      <td>symptoms_labs</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19728 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence          class  \\\n",
       "0      A sixteen year-old girl, presented to our Outp...  symptoms_labs   \n",
       "1      She was not able to maintain an erect posture ...  symptoms_labs   \n",
       "2      She would keep her head turned to the right an...  symptoms_labs   \n",
       "3      There was a sideways bending of the back in th...  symptoms_labs   \n",
       "4      To counter the abnormal positioning of the bac...  symptoms_labs   \n",
       "...                                                  ...            ...   \n",
       "19963  No significant muscle atrophy was present, and...  symptoms_labs   \n",
       "19964  The physical examination showed that both of h...  symptoms_labs   \n",
       "19965  Both knees were very soft and could touch the ...  symptoms_labs   \n",
       "19966  Upon palpation, the continuity of the quadrice...  symptoms_labs   \n",
       "19967  In addition, the patient could not complete kn...  symptoms_labs   \n",
       "\n",
       "       case_id  \n",
       "0           -1  \n",
       "1           -1  \n",
       "2           -1  \n",
       "3           -1  \n",
       "4           -1  \n",
       "...        ...  \n",
       "19963      912  \n",
       "19964      915  \n",
       "19965      915  \n",
       "19966      915  \n",
       "19967      915  \n",
       "\n",
       "[19728 rows x 3 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def aug_preprocess(dataset):\n",
    "    cleaned_ds = dataset.copy()\n",
    "\n",
    "    # For loggin purposes\n",
    "    N = cleaned_ds.shape[0]\n",
    "    logger.info(f\"Found {N} rows\")\n",
    "    num_renames = cleaned_ds[cleaned_ds['class'].isin(['symptoms_lbs', 'symptoms_lads'])].shape[0]\n",
    "    logger.info(f\"Fixed class naming for {num_renames} rows ({(num_renames / N)*100} %)\")\n",
    "    \n",
    "    # Fix naming of some classes\n",
    "    cleaned_ds['class'] = cleaned_ds['class'].replace({'symptoms_lbs': 'symptoms_labs', 'symptoms_lads': 'symptoms_labs'})\n",
    "    \n",
    "    pos_invalids = cleaned_ds[~cleaned_ds['class'].isin(classes)]\n",
    "    swapped_values = pos_invalids[pos_invalids['sentence'].isin(classes)]    # Rows with swapped values\n",
    "    invalid_classes = pos_invalids[pos_invalids['class'].str.lower().isin(['', '0', '__', 'None', '[]', 'False', 'The', 'No'])]  # collect empty sentence and classes (Note that doing it here will catch the invalid swapped sentences as well)\n",
    "    ignore_classes = pos_invalids[pos_invalids['sentence'].str.contains('not a sentence')]\n",
    "    invalid_sentences = pos_invalids[pos_invalids['sentence'].str.lower().isin(['', '__', 'None', '[]', 'False', '()'])]\n",
    "\n",
    "    invalids = pos_invalids.loc[invalid_classes.index.union(invalid_sentences.index.union(ignore_classes.index))]\n",
    "    # invalids = pos_invalids.loc[invalid_classes.index.union(invalid_sentences.index)]\n",
    "    # invalids = pos_invalids[pos_invalids ['class'].isin(['', '0', '[]', 'False'])]   # Clearly invalids, temp drop to remove from our ceaned list\n",
    "    nonstd_classes = pos_invalids.drop(index=swapped_values.index.union(invalids.index))   # Get list of non-standard class rows\n",
    "    # print(ignore_classes.index[0] in list(nonstd_classes.index))\n",
    "    # print(ignore_classes.index[0] in list(invalids.index))\n",
    "    # print(nonstd_classes[nonstd_classes['sentence'].str.contains('not a sentence')])\n",
    "\n",
    "    # Get list of classes that can be classified as \"other\" with enough occurence (non-outliery)\n",
    "    # value_cnts = nonstd_classes['class'].value_counts()\n",
    "    # other_classes = value_cnts[value_cnts >= 5].index.tolist()\n",
    "    # other_class_rows = nonstd_classes[nonstd_classes['class'].isin(other_classes)]\n",
    "    # other_class_rows = other_class_rows[~other_class_rows['sentence'].str.contains('thought_process')]\n",
    "    # other_class_rows = other_class_rows[~other_class_rows['sentence'].str.contains('symptoms_labs')]\n",
    "    # other_class_indices = other_class_rows[~other_class_rows['sentence'].str.contains('diagnosis')].index  # Note we get rid of this because bad classification when it should've been \"diagnosis\", also removes \"diagnosis: \" sentences\n",
    "    # print(other_class_indices)\n",
    "    # print(value_cnts[value_cnts >= 5])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'symptoms_lbs'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'A'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'classification'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'No'])\n",
    "    # display(cleaned_ds[cleaned_ds['class'] == 'The'])\n",
    "\n",
    "    swapped_indices = swapped_values.index\n",
    "    cleaned_ds.loc[swapped_indices, ['sentence', 'class']] = cleaned_ds.loc[swapped_indices, ['class', 'sentence']].values # swap the values in indices where it's swapped\n",
    "    # cleaned_ds.loc[other_class_indices, 'class'] = 'other'\n",
    "    # cleaned_ds['class'] = cleaned_ds['class'].apply(lambda x: 'other' if x in other_classes else x)  # relabel non-standards to 'other'\n",
    "    drop_indices = cleaned_ds[~cleaned_ds['class'].isin(classes)].index\n",
    "    # print(ignore_classes.index in list(drop_indices))\n",
    "    # print(ignore_classes.index)\n",
    "    # print(list(drop_indices))\n",
    "    \n",
    "    cleaned_ds = cleaned_ds.drop(index=drop_indices) # drop all others that aren't in our list of classes + 'other' (basically all invalids)\n",
    "\n",
    "    # Summary\n",
    "    num_reclass = cleaned_ds[cleaned_ds['class'] == 'other'].shape[0]\n",
    "    # logger.info(f\"Re-classified {len(other_classes)} classes as 'other', or {num_reclass} rows ({(num_reclass / N)*100} %)\")\n",
    "    logger.info(f'Swapped class and sentence values of {swapped_indices.shape[0]} rows ({(swapped_indices.shape[0] / N)*100} %)')\n",
    "    logger.info(f'Dropped {drop_indices.shape[0]} invalid rows ({(drop_indices.shape[0] / N)*100} %)')\n",
    "\n",
    "    # change case_id into int\n",
    "    cleaned_ds['case_id'] = cleaned_ds['case_id'].astype(int)\n",
    "    # print(cleaned_ds[cleaned_ds['sentence'].str.contains('not a sentence')])\n",
    "    \n",
    "    return cleaned_ds\n",
    "\n",
    "aug_preprocess(processed_datasets['aug_med_notes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5643b621-e1f5-48c4-b7b6-69a0c4569c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "proc_funcs = {'mimic4': mimic_preprocess, 'aug_med_notes': aug_preprocess}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2dc24bb2-7506-4e5a-9115-a2951271fbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 03:22:11,447 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "2025-06-03 03:22:11,448 || INFO || MedRL-CoT Preprocess - Cleaning up aug_med_notes dataset\n",
      "2025-06-03 03:22:11,450 || INFO || MedRL-CoT Preprocess - Found 19968 rows\n",
      "2025-06-03 03:22:11,452 || INFO || MedRL-CoT Preprocess - Fixed class naming for 21 rows (0.10516826923076923 %)\n",
      "2025-06-03 03:22:11,466 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 131 rows (0.6560496794871795 %)\n",
      "2025-06-03 03:22:11,468 || INFO || MedRL-CoT Preprocess - Dropped 240 invalid rows (1.201923076923077 %)\n",
      "2025-06-03 03:22:11,471 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "2025-06-03 03:22:11,473 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "2025-06-03 03:22:11,474 || INFO || MedRL-CoT Preprocess - Cleaning up mimic4 dataset\n",
      "2025-06-03 03:22:11,476 || INFO || MedRL-CoT Preprocess - Found 29654 rows\n",
      "2025-06-03 03:22:11,479 || INFO || MedRL-CoT Preprocess - Fixed class naming for 282 rows (0.9509678289606799 %)\n",
      "2025-06-03 03:22:11,503 || INFO || MedRL-CoT Preprocess - Re-classified 18 classes as 'other', or 1073 rows (3.618398866931948 %)\n",
      "2025-06-03 03:22:11,504 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 571 rows (1.925541242328185 %)\n",
      "2025-06-03 03:22:11,505 || INFO || MedRL-CoT Preprocess - Dropped 169 invalid rows (0.5699062521076415 %)\n",
      "2025-06-03 03:22:11,508 || INFO || MedRL-CoT Preprocess - ==================================================\n"
     ]
    }
   ],
   "source": [
    "preprocessed_datasets = dict()\n",
    "for key, item in processed_datasets.items():\n",
    "    logger.info(\"=\" * 50)\n",
    "    logger.info(f\"Cleaning up {key} dataset\")\n",
    "    # processed_datasets[key] = mimic_preprocess(processed_datasets[key])\n",
    "    # mimic_preprocess(processed_datasets[key])\n",
    "    preprocessed_datasets[key] = proc_funcs[key](processed_datasets[key])\n",
    "    logger.info(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "970f8205-b8fb-4fd7-8c7a-1bb540cd4085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aug_med_notes', 'mimic4'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4410b801-5e22-47e8-8a7b-89c99c484140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "        15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
       "        41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,\n",
       "        54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n",
       "        67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
       "        80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
       "        93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
       "       106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
       "       119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
       "       132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
       "       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
       "       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
       "       171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
       "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
       "       197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "       210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
       "       223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
       "       236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
       "       249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261,\n",
       "       262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
       "       275, 276, 277, 278, 279, 280, 281, 282, 283])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_datasets['mimic4']['case_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "073ba94c-9033-41e0-977e-3663c6e95118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def join_sentence_class(group):\n",
    "#     return ' '.join(f\"{row['sentence']} <{row['class']}>\" for _, row in group.iterrows())\n",
    "    \n",
    "# # preprocessed_datasets['mimic4'].groupby('case_id').apply(join_sentence_class).reset_index(name='full_class_case').sort_values('case_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "81b6f92f-91dc-48cd-bbdc-03b29b06270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases_datasets = dict()\n",
    "# for key, dataset in preprocessed_datasets.items():\n",
    "#     cases_datasets[key] = dataset.groupby('case_id').apply(join_sentence_class).reset_index(name='full_class_case').sort_values('case_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "091b4a97-8f38-4cdc-855f-74fa96912fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases_datasets['aug_med_notes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4af634f5-3278-41c4-b4f2-ad4689448f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases_datasets['aug_med_notes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b2daf529-4d0a-49f9-87e9-4baa1d6e738a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "      <th>case_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentence, class, case_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_datasets['aug_med_notes'][preprocessed_datasets['aug_med_notes']['class'] == 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a78ec6d9-3ab1-4522-9810-d475db8e3f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 03:22:14,686 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "2025-06-03 03:22:14,687 || INFO || MedRL-CoT Preprocess - Cleaning up aug_med_notes dataset\n",
      "2025-06-03 03:22:14,689 || INFO || MedRL-CoT Preprocess - Found 19968 rows\n",
      "2025-06-03 03:22:14,691 || INFO || MedRL-CoT Preprocess - Fixed class naming for 21 rows (0.10516826923076923 %)\n",
      "2025-06-03 03:22:14,705 || INFO || MedRL-CoT Preprocess - Re-classified 5 classes as 'other', or 76 rows (0.38060897435897434 %)\n",
      "2025-06-03 03:22:14,707 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 131 rows (0.6560496794871795 %)\n",
      "2025-06-03 03:22:14,707 || INFO || MedRL-CoT Preprocess - Dropped 164 invalid rows (0.8213141025641026 %)\n",
      "2025-06-03 03:22:14,709 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "2025-06-03 03:22:14,710 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "2025-06-03 03:22:14,711 || INFO || MedRL-CoT Preprocess - Cleaning up mimic4 dataset\n",
      "2025-06-03 03:22:14,713 || INFO || MedRL-CoT Preprocess - Found 29654 rows\n",
      "2025-06-03 03:22:14,716 || INFO || MedRL-CoT Preprocess - Fixed class naming for 282 rows (0.9509678289606799 %)\n",
      "2025-06-03 03:22:14,735 || INFO || MedRL-CoT Preprocess - Swapped class and sentence values of 571 rows (1.925541242328185 %)\n",
      "2025-06-03 03:22:14,737 || INFO || MedRL-CoT Preprocess - Dropped 1242 invalid rows (4.1883051190395895 %)\n",
      "2025-06-03 03:22:14,738 || INFO || MedRL-CoT Preprocess - ==================================================\n",
      "/tmp/ipykernel_430080/2747992724.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cases_datasets[key] = dataset.groupby('case_id').apply(xy_split_processing).reset_index().drop(columns=['case_id'])\n",
      "/tmp/ipykernel_430080/2747992724.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cases_datasets[key] = dataset.groupby('case_id').apply(xy_split_processing).reset_index().drop(columns=['case_id'])\n",
      "2025-06-03 03:22:16,618 || INFO || DataManager - Loading datasets: ['aug_med_notes', 'mimic4']\n",
      "2025-06-03 03:22:16,622 || INFO || DataManager - AGBonnet/augmented-clinical-notes dataset already exists in disk. If the dataset is giving errors or you'd like a fresh install, delete the /mnt/e/UCSD/ECE285DGM/ECE285DGMProject/data/aug_med_notes/train directory.\n",
      "2025-06-03 03:22:16,623 || INFO || DataManager - Loading saved hugginface AGBonnet/augmented-clinical-notes dataset.\n",
      "2025-06-03 03:22:16,625 || ERROR || DataManager - Error loading AGBonnet/augmented-clinical-notes dataset from local!\n",
      "2025-06-03 03:22:16,628 || INFO || DataManager - discharge.csv.gz dataset already exists in disk as huggin_face dataset. If the dataset is giving errors or you'd like a fresh install, delete the /mnt/e/UCSD/ECE285DGM/ECE285DGMProject/data/mimic4/hf directory.\n",
      "2025-06-03 03:22:16,629 || INFO || DataManager - Loading saved hugginface discharge.csv.gz dataset.\n",
      "2025-06-03 03:22:16,793 || INFO || DataManager - Successfully loaded hugging_face of discharge.csv.gz as key mimic4\n",
      "2025-06-03 03:22:16,794 || INFO || DataManager - Successfully loaded 2 datasets: ['aug_med_notes', 'mimic4']\n"
     ]
    }
   ],
   "source": [
    "def xy_split_processing(group):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for _, row in group.iterrows():\n",
    "        if row['class'] == 'symptoms_labs' or row['class'] == 'other':\n",
    "            X.append(row)\n",
    "        else:\n",
    "            Y.append(row)\n",
    "\n",
    "    X_case = ' '.join([str(row['sentence']) for row in X])\n",
    "    Y_case = ' '.join([f\"{row['sentence']} <{row['class']}> \" for row in Y])\n",
    "    \n",
    "    return pd.Series({'X': X_case, 'Y': Y_case})\n",
    "\n",
    "import medrlcot.preprocessing as mp\n",
    "preprocessed_datasets = mp.preprocess_datasets()\n",
    "\n",
    "# Combine cases into one for cases as example for SFT\n",
    "cases_datasets = dict()\n",
    "for key, dataset in preprocessed_datasets.items():\n",
    "    cases_datasets[key] = dataset.groupby('case_id').apply(xy_split_processing).reset_index().drop(columns=['case_id'])\n",
    "\n",
    "import os\n",
    "from medrlcot import data_manager\n",
    "import medrlcot.config.env as mce\n",
    "model_cfg_path = os.path.join(os.getcwd(), \"medrlcot/config/.env\")\n",
    "medrlcot_config = mce.MedRL_CoT(model_cfg_path)\n",
    "raw_datasets = data_manager.load_datasets(medrlcot_config.datasets, data_dir=medrlcot_config.data_dir)  # Load raw dataset (original cases) for RM\n",
    "\n",
    "# Create customd dataset obj\n",
    "# cases_data = data_manager.Dataset(cases_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6b01e90e-03f3-4f59-873c-37518b17bbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 03:58:34,075 || INFO || DataManager - Using train-val split: [0.75, 0.25]\n",
      "2025-06-03 03:58:34,076 || INFO || DataManager - Splitting aug_med_notes dataset.\n",
      "2025-06-03 03:58:34,079 || INFO || DataManager - Splitting mimic4 dataset.\n",
      "2025-06-03 03:58:34,082 || INFO || DataManager - Creating a single joint dataset of dict_keys(['aug_med_notes', 'mimic4']) dataset splits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[561, 211]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      The goal of no headache more than twice a week...\n",
       "1      Local anesthesia containing 1.8 mL lidocaine a...\n",
       "2      A 65-year-old male, without any comorbidities ...\n",
       "3      On examination there was firm, bony expansion ...\n",
       "4      Five years later, a CT scan indicated that the...\n",
       "                             ...                        \n",
       "767    PMH: Chronic Diastolic Heart Failure, Aortic s...\n",
       "768    She reports that she swallowed an underwire of...\n",
       "769    Chief Complaint: chest pain, SOB After dischar...\n",
       "770    Chief Complaint: Major Surgical or Invasive Pr...\n",
       "771    History of Present Illness: Patient is a ___ y...\n",
       "Name: X, Length: 772, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data_manager.Dataset(cases_datasets)\n",
    "print([len(t) for t in test.data['train'][0]])\n",
    "pd.concat(test.data['train'][0], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fef06e51-633a-44b7-b765-88ab6aee3066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A sixteen year-old girl, presented to our Outp...</td>\n",
       "      <td>The introduction and subsequent withdrawal of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Her past medical history included mild Multipl...</td>\n",
       "      <td>A 34 year old Persian woman, gravida 1, para 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 60-year-old female who was previously health...</td>\n",
       "      <td>She was treated with thrombolysis and endovasc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>classification &lt;diagnosis&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The chief complains included bilateral hips an...</td>\n",
       "      <td>Staged bilateral total hip arthroplasties were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>The patient was a 60-year-old man who referred...</td>\n",
       "      <td>A 45 mm × 37 mm pseudoaneurysm in lateral side...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>A 38 year old Vietnamese man was admitted with...</td>\n",
       "      <td>The working diagnosis was a collection seconda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>A 30-year-old woman was admitted to our instit...</td>\n",
       "      <td>She had undergone endovascular trapping of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>A 51-year-old hypertensive Pakistani male pati...</td>\n",
       "      <td>The patient underwent general anesthesia for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>An 18-year-old male patient (height 140 cm, we...</td>\n",
       "      <td>The patient was diagnosed with spinal muscular...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>748 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     X  \\\n",
       "0    A sixteen year-old girl, presented to our Outp...   \n",
       "1    Her past medical history included mild Multipl...   \n",
       "2    A 60-year-old female who was previously health...   \n",
       "3                                                        \n",
       "4    The chief complains included bilateral hips an...   \n",
       "..                                                 ...   \n",
       "743  The patient was a 60-year-old man who referred...   \n",
       "744  A 38 year old Vietnamese man was admitted with...   \n",
       "745  A 30-year-old woman was admitted to our instit...   \n",
       "746  A 51-year-old hypertensive Pakistani male pati...   \n",
       "747  An 18-year-old male patient (height 140 cm, we...   \n",
       "\n",
       "                                                     Y  \n",
       "0    The introduction and subsequent withdrawal of ...  \n",
       "1    A 34 year old Persian woman, gravida 1, para 0...  \n",
       "2    She was treated with thrombolysis and endovasc...  \n",
       "3                          classification <diagnosis>   \n",
       "4    Staged bilateral total hip arthroplasties were...  \n",
       "..                                                 ...  \n",
       "743  A 45 mm × 37 mm pseudoaneurysm in lateral side...  \n",
       "744  The working diagnosis was a collection seconda...  \n",
       "745  She had undergone endovascular trapping of the...  \n",
       "746  The patient underwent general anesthesia for t...  \n",
       "747  The patient was diagnosed with spinal muscular...  \n",
       "\n",
       "[748 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_datasets['aug_med_notes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a0c2dc7d-438e-4e22-80d9-23e3e09fb807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1037, 7032,  ..., 1037, 6578,  102],\n",
       "        [ 101, 2014, 2627,  ...,    0,    0,    0],\n",
       "        [ 101, 1037, 3438,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 1037, 2382,  ...,    0,    0,    0],\n",
       "        [ 101, 1037, 4868,  ...,    0,    0,    0],\n",
       "        [ 101, 2019, 2324,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer(list(cases_datasets['aug_med_notes']['X']), padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "610680dc-3058-40b0-ba52-1ae28a95fac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      A sixteen year-old girl, presented to our Outp...\n",
       "1      Her past medical history included mild Multipl...\n",
       "2      A 60-year-old female who was previously health...\n",
       "3                                                       \n",
       "4      The chief complains included bilateral hips an...\n",
       "                             ...                        \n",
       "743    The patient was a 60-year-old man who referred...\n",
       "744    A 38 year old Vietnamese man was admitted with...\n",
       "745    A 30-year-old woman was admitted to our instit...\n",
       "746    A 51-year-old hypertensive Pakistani male pati...\n",
       "747    An 18-year-old male patient (height 140 cm, we...\n",
       "Name: X, Length: 748, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_datasets['aug_med_notes']['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1b78f-0f78-4011-9270-b3e3ecfe14f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ea78e-f58c-4e93-a078-dd644f267828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca4695-8d06-4388-bfa2-6e673f19c333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a9653c-0e0c-4e1b-90f6-f7a1d078478d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1d4bb-c6d9-4a71-a35a-eaa11746b28f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4aac88-58ed-4140-ad1c-06dface6090d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a63ab-b665-4c57-90bc-2063cdd9ae1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
