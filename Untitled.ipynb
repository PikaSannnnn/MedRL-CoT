{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93cd76d-8aed-40d5-8ee0-c24566c28480",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b682f71a-59eb-4552-b60c-74081bc2dddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install required modules\n",
    "# !pip install datasets dotenv torch SentencePiece accelerate huggingface_hub\n",
    "# !pip install -U bitsandbytes\n",
    "# !pip install --force-reinstall transformers==4.35.2\n",
    "# !pip install --force-reinstall --upgrade bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3daee32-9beb-4303-b18e-806ffc111d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 05:41:17,293 || INFO || Logger - Setup for MedRL-CoT's log done. This is the beginning of the log.\n",
      "2025-05-30 05:41:17,293 || INFO || DataManager - Loading datasets: ['aug_med_notes', 'mimic4']\n",
      "2025-05-30 05:41:17,294 || INFO || DataManager - AGBonnet/augmented-clinical-notes dataset already exists in disk. If the dataset is giving errors or you'd like a fresh install, delete the /home/ubuntu/medrlcot/data/aug_med_notes directory.\n",
      "2025-05-30 05:41:17,295 || INFO || DataManager - Loading saved hugginface AGBonnet/augmented-clinical-notes dataset.\n",
      "2025-05-30 05:41:17,357 || INFO || DataManager - Successfully loaded AGBonnet/augmented-clinical-notes as key aug_med_notes\n",
      "2025-05-30 05:41:17,358 || ERROR || DataManager - Dataset not found in local. Due to long web-download time, this dataset must be manually installed to local with the dataset expected to be saved as /home/ubuntu/medrlcot/data/mimic4/discharge.csv.gz.\n",
      "2025-05-30 05:41:17,359 || WARNING || DataManager - Failed to load 1 dataset: {'mimic4'}!\n",
      "2025-05-30 05:41:17,359 || INFO || DataManager - Successfully loaded 1 datasets: ['aug_med_notes']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated new log file logs/medrlcot003.log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aug_med_notes': Dataset({\n",
       "     features: ['idx', 'note', 'full_note', 'conversation', 'summary'],\n",
       "     num_rows: 30000\n",
       " })}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from medrlcot.config.env import MedRL_CoT\n",
    "from medrlcot import data_manager\n",
    "from medrlcot.medrlcot_logger import setup_logger\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# env = load_dotenv()\n",
    "# model_cfg_path = os.path.join(os.getcwd(), os.getenv('model_config'))\n",
    "model_cfg_path = os.path.join(os.getcwd(), \"medrlcot/config/.env\")\n",
    "medrlcot_config = MedRL_CoT(model_cfg_path)\n",
    "\n",
    "setup_logger()\n",
    "logger = logging.getLogger(\"MedRL-CoT Setup\")\n",
    "\n",
    "# Download datasets\n",
    "datasets = data_manager.load_datasets(medrlcot_config.datasets, data_dir=medrlcot_config.data_dir)\n",
    "\n",
    "datasets\n",
    "# print(datasets['aug_med_notes']['full_note'][0])\n",
    "# data_manager.load_datasets(medrlcot_config.datasets, data_dir=medrlcot_config.data_dir, load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703d41c3-c82d-4503-992b-a7aefca1e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [f for f in os.listdir(\"/Users/sdong/Documents/UCSD/ECE285/ECE285DGMProject/data/aug_med_notes/train\") if f.endswith(\".arrow\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfd6cee1-d1a8-4b68-8759-d48f2de94507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Load model directly\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.3-70B-Instruct\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.3-70B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c1f8408-ff49-4241-b54a-501b3790ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install flash_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1777f8cb-a193-4dc0-8fe6-48db303acc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "2025-05-30 05:55:50,617 || INFO || accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b4ac1b61e1490fa13f1c01521b0314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import bitsandbytes\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\", use_fast=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\", torch_dtype=torch.float16, \n",
    "                                             device_map=\"auto\", load_in_8bit=False, load_in_4bit=True)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "832400ec-0b0c-47db-b647-a98565219cf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A a sixteen year-old girl, presented to our Outpatient department with the complaints of discomfort in the neck and lower back as well as restriction of body movements. She was not able to maintain an erect posture and would tend to fall on either side while standing up from a sitting position. She would keep her head turned to the right and upwards due to the sustained contraction of the neck muscles. There was a sideways bending of the back in the lumbar region. To counter the abnormal positioning of the back and neck, she would keep her limbs in a specific position to allow her body weight to be supported. Due to the restrictions with the body movements at the neck and in the lumbar region, she would require assistance in standing and walking. She would require her parents to help her with daily chores, including all activities of self-care.\\\\nShe had been experiencing these difficulties for the past four months since when she was introduced to olanzapine tablets for the control of her exacerbated mental illness. This was not her first experience with this drug over the past seven years since she had been diagnosed with bipolar affective disorder. Her first episode of the affective disorder was that of mania at the age of eleven which was managed with the use of olanzapine tablets in 2.5–10 mg doses per day at different times. The patient developed pain and discomfort in her neck within the second week of being put on tablet olanzapine at a dose of 5 mg per day. This was associated with a sustained and abnormal contraction of the neck muscles that would pull her head to the right in an upward direction. These features had persisted for the first three years of her illness with a varying intensity, distress, and dysfunction which would tend to correlate with the dose of olanzapine. Apart from a brief period of around three weeks when she was given tablet trihexyphenidyl 4 mg per day for rigidity in her upper limbs, she was not prescribed any other psychotropic medication. The rigidity showed good response to this medication which was subsequently stopped. The introduction and subsequent withdrawal of this medication did not bring about any change in the sustained abnormal contraction of her neck muscles.\\\\nImprovement and subsequent remission of the mood symptoms of the patient provided the treatment team with an opportunity to stop olanzapine. The discomfort in the neck and the abnormal movement of the neck muscles persisted over the next three months’ period when she was off olanzapine without any significant change, even with a trial of propranolol, trihexyphenidyl, and phenargan injection. Reintroduction of olanzapine (at a dose of 2.5 mg per day) after a gap of three months for the reemergence of some behavioral features led to a slight aggravation of the already existing abnormal movement and posturing of the neck.\\\\nWith improvement in the clinical picture, olanzapine was reduced and stopped. She was put on tablet sodium valproate, 1000 mg per day during this period for the stabilization of her mood when she was also given escitalopram for a period of three months for her depressive features. The patient responded well to this change in medication, but she developed amenorrhea for which no cause was established after a detailed gynecological evaluation. Keeping in mind the possibility of valproate-induced menstrual disturbance, she was shifted to tablet lithium 450 mg per day. The patient was well maintained on this medication for a period of around two years. However, she developed hypothyroidism for which eltroxin was introduced at a dose of 50 micrograms per day.\\\\nDuring this period of two years and seven months, the abnormal contraction of the neck muscles and the abnormal positioning of the head improved slightly, and with the improvement, it would cause less discomfort and interference in her activities. However, these movements failed to disappear completely. Another exacerbation of the mood symptoms in the form of mania warranted a need for the introduction of olanzapine (by a different treatment team) and the patient was reintroduced to 10 mg olanzapine on a daily basis, which led to the current presentation as described earlier.\\\\nAfter the case was seen at our institute, the psychotropic medications were stopped as her mood symptoms had remitted and she was put on tablet tetrabenazine (built up to 75 mg per day in divided doses) with which the patient had started showing some response with an improvement in abnormal movements of the muscles of the neck as well as the back. She is now able to stand with support and can do some daily chores on her own. The pain and discomfort in the back and neck have also reduced.\\\\nDuring the course of the illness, the patient has been investigated for the presence of any neurological illness as the cause of her abnormal movements. Her MRI scan of the brain, serum and urine copper levels, slit lamp microscopy for the KF ring, complete blood count, TLC, DLC, and USG of the abdomen did not reveal any abnormalities. Her thyroid function tests were deranged subsequent to the introduction of tablet lithium carbonate which was restored to normal after the introduction of tablet eltroxin.\\\\nDystonia is a syndrome of sustained muscle contractions that produce twisting and repetitive movements or abnormal postures. The descriptions of the extent and severity of muscle involvement are variable, ranging from intermittent contraction limited to a single body region, to generalized dystonia involving the limbs and axial muscles.\\\\nEver since the introduction of the term, “dystonia” by Oppenhiem in the early part of the twentieth century, it has been an area of focused attention of the neurologists. In 1973, Keegan and Rajput introduced the term, “” to describe drug-induced, sustained muscle spasm causing repetitive movements or abnormal postures. “” was a term introduced by Burke in 1982, the description of which required the presence of chronic dystonia, a history of antipsychotic drug treatment preceding or concurrent with the onset of dystonia, the exclusion of known causes of secondary dystonia by appropriate clinical and laboratory evaluation, and a negative family history of dystonia for definitive diagnosis.\\\\nThe dystonia could be classified based on the region(s) of the body involved. Involvement of isolated regions like the face, neck, and arms would be labeled as focal dystonia, whereas simultaneous involvement of two or more contiguous areas would be called segmental dystonia. When the clinical picture is that of involvement of two or more noncontiguous regions, the label used is, “multifocal” and the involvement of one leg and one other body region makes it the generalized type.\\\\nThe symptoms of tardive dystonia could begin even after a few days or weeks of exposure to the offending agent. Tardive dystonia is prevalent in 0.5–21.6% of the patients who are treated with neuroleptics.\\\\nThe syndrome of tardive dystonia has been reported with most of the typical antipsychotics.[] It has been associated with the atypical antipsychotics, namely risperidone, olanzapine, quetiapine, and aripiprazole. Reports of tardive dystonia developing with the use of atypical antipsychotics have been predominantly in the cases of nonaffective psychosis and in the adult population in the age ranges of the midthirties and forties. Our case is the first case of an affective illness in an adolescent girl developing tardive dystonia on olanzapine. The aggravation of the clinical features with the inadvertent reintroduction of the medication suggests olanzapine is the offending agent. With the growing acceptance of olanzapine as the first-line therapy for the manic phase of bipolar illness and as a mood stabilizer for the maintenance therapy, one needs to be cautious about the emergence of this troublesome adverse effect of this therapy. The patient has shown some response to the introduction of tetrabenazine.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_note=datasets['aug_med_notes']['full_note'][0]\n",
    "example_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c903e73a-8bd2-48b3-8d6f-f771372613f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_note = \"\"\"A a sixteen year-old girl, presented to our Outpatient department with the complaints of discomfort in the neck and lower back as well as restriction of body movements. She was not able to maintain an erect posture and would tend to fall on either side while standing up from a sitting position. She would keep her head turned to the right and upwards due to the sustained contraction of the neck muscles. There was a sideways bending of the back in the lumbar region. To counter the abnormal positioning of the back and neck, she would keep her limbs in a specific position to allow her body weight to be supported. Due to the restrictions with the body movements at the neck and in the lumbar region, she would require assistance in standing and walking. She would require her parents to help her with daily chores, including all activities of self-care.\\nShe had been experiencing these difficulties for the past four months since when she was introduced to olanzapine tablets for the control of her exacerbated mental illness. This was not her first experience with this drug over the past seven years since she had been diagnosed with bipolar affective disorder. Her first episode of the affective disorder was that of mania at the age of eleven which was managed with the use of olanzapine tablets in 2.5–10 mg doses per day at different times. The patient developed pain and discomfort in her neck within the second week of being put on tablet olanzapine at a dose of 5 mg per day. This was associated with a sustained and abnormal contraction of the neck muscles that would pull her head to the right in an upward direction. These features had persisted for the first three years of her illness with a varying intensity, distress, and dysfunction which would tend to correlate with the dose of olanzapine. Apart from a brief period of around three weeks when she was given tablet trihexyphenidyl 4 mg per day for rigidity in her upper limbs, she was not prescribed any other psychotropic medication. The rigidity showed good response to this medication which was subsequently stopped. The introduction and subsequent withdrawal of this medication did not bring about any change in the sustained abnormal contraction of her neck muscles.\\nImprovement and subsequent remission of the mood symptoms of the patient provided the treatment team with an opportunity to stop olanzapine. The discomfort in the neck and the abnormal movement of the neck muscles persisted over the next three months’ period when she was off olanzapine without any significant change, even with a trial of propranolol, trihexyphenidyl, and phenargan injection. Reintroduction of olanzapine (at a dose of 2.5 mg per day) after a gap of three months for the reemergence of some behavioral features led to a slight aggravation of the already existing abnormal movement and posturing of the neck.\\nWith improvement in the clinical picture, olanzapine was reduced and stopped. She was put on tablet sodium valproate, 1000 mg per day during this period for the stabilization of her mood when she was also given escitalopram for a period of three months for her depressive features. The patient responded well to this change in medication, but she developed amenorrhea for which no cause was established after a detailed gynecological evaluation. Keeping in mind the possibility of valproate-induced menstrual disturbance, she was shifted to tablet lithium 450 mg per day. The patient was well maintained on this medication for a period of around two years. However, she developed hypothyroidism for which eltroxin was introduced at a dose of 50 micrograms per day.\\nDuring this period of two years and seven months, the abnormal contraction of the neck muscles and the abnormal positioning of the head improved slightly, and with the improvement, it would cause less discomfort and interference in her activities. However, these movements failed to disappear completely. Another exacerbation of the mood symptoms in the form of mania warranted a need for the introduction of olanzapine (by a different treatment team) and the patient was reintroduced to 10 mg olanzapine on a daily basis, which led to the current presentation as described earlier.\\nAfter the case was seen at our institute, the psychotropic medications were stopped as her mood symptoms had remitted and she was put on tablet tetrabenazine (built up to 75 mg per day in divided doses) with which the patient had started showing some response with an improvement in abnormal movements of the muscles of the neck as well as the back. She is now able to stand with support and can do some daily chores on her own. The pain and discomfort in the back and neck have also reduced.\\nDuring the course of the illness, the patient has been investigated for the presence of any neurological illness as the cause of her abnormal movements. Her MRI scan of the brain, serum and urine copper levels, slit lamp microscopy for the KF ring, complete blood count, TLC, DLC, and USG of the abdomen did not reveal any abnormalities. Her thyroid function tests were deranged subsequent to the introduction of tablet lithium carbonate which was restored to normal after the introduction of tablet eltroxin.\\nDystonia is a syndrome of sustained muscle contractions that produce twisting and repetitive movements or abnormal postures. The descriptions of the extent and severity of muscle involvement are variable, ranging from intermittent contraction limited to a single body region, to generalized dystonia involving the limbs and axial muscles.\\nEver since the introduction of the term, “dystonia” by Oppenhiem in the early part of the twentieth century, it has been an area of focused attention of the neurologists. In 1973, Keegan and Rajput introduced the term, “” to describe drug-induced, sustained muscle spasm causing repetitive movements or abnormal postures. “” was a term introduced by Burke in 1982, the description of which required the presence of chronic dystonia, a history of antipsychotic drug treatment preceding or concurrent with the onset of dystonia, the exclusion of known causes of secondary dystonia by appropriate clinical and laboratory evaluation, and a negative family history of dystonia for definitive diagnosis.\\nThe dystonia could be classified based on the region(s) of the body involved. Involvement of isolated regions like the face, neck, and arms would be labeled as focal dystonia, whereas simultaneous involvement of two or more contiguous areas would be called segmental dystonia. When the clinical picture is that of involvement of two or more noncontiguous regions, the label used is, “multifocal” and the involvement of one leg and one other body region makes it the generalized type.\\nThe symptoms of tardive dystonia could begin even after a few days or weeks of exposure to the offending agent. Tardive dystonia is prevalent in 0.5–21.6% of the patients who are treated with neuroleptics.\\nThe syndrome of tardive dystonia has been reported with most of the typical antipsychotics.[] It has been associated with the atypical antipsychotics, namely risperidone, olanzapine, quetiapine, and aripiprazole. Reports of tardive dystonia developing with the use of atypical antipsychotics have been predominantly in the cases of nonaffective psychosis and in the adult population in the age ranges of the midthirties and forties. Our case is the first case of an affective illness in an adolescent girl developing tardive dystonia on olanzapine. The aggravation of the clinical features with the inadvertent reintroduction of the medication suggests olanzapine is the offending agent. With the growing acceptance of olanzapine as the first-line therapy for the manic phase of bipolar illness and as a mood stabilizer for the maintenance therapy, one needs to be cautious about the emergence of this troublesome adverse effect of this therapy. The patient has shown some response to the introduction of tetrabenazine.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29f54a44-7692-49c7-9fcb-4d7ee1be4124",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = example_note.split('.')\n",
    "chunks = example_note.split('\\\\n')\n",
    "# len(example_note.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb1151dc-4aef-4d29-8fc5-887bcb992982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(sentences)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fab88b10-3989-4998-bbb1-b8bee550f865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A a sixteen year-old girl, presented to our Outpatient department with the complaints of discomfort in the neck and lower back as well as restriction of body movements. She was not able to maintain an erect posture and would tend to fall on either side while standing up from a sitting position. She would keep her head turned to the right and upwards due to the sustained contraction of the neck muscles. There was a sideways bending of the back in the lumbar region. To counter the abnormal positioning of the back and neck, she would keep her limbs in a specific position to allow her body weight to be supported. Due to the restrictions with the body movements at the neck and in the lumbar region, she would require assistance in standing and walking. She would require her parents to help her with daily chores, including all activities of self-care.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "05102934-4aaa-4e0a-8212-a333c21a4f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initit_prompt = f\"\"\"<|im_start|>system\n",
    "# You are a medical assistant helping organize a patient's clinical notes that will presented sentence by sentence.\n",
    "\n",
    "# Your tasks is to classify the sentence I give you as one of the following keys \"symptoms_labs\", \"thought_process\", and \"diagnosis\":\n",
    "# symptoms_labs: \n",
    "# - All references to symptoms they are currently or was experiencing, test results, or lab findings\n",
    "# thought_process: \n",
    "# - The reasoning or consideration made by the doctor\n",
    "# diagnosis: \n",
    "# - The doctor's final or working diagnosis\n",
    "\n",
    "# Respond with only the category of the sentence\n",
    "# <|im_end|>\n",
    "# \"\"\"\n",
    "# Respond with a JSON containing the sentence as key and the classification as the value: \"symptoms_labs\", \"thought_process\", and \"diagnosis\". \n",
    "initit_prompt = \"\"\"<|im_start|>system\n",
    "You are a medical assistant helping organize a patient's clinical notes  that will presented by paragraph/chunk.\n",
    "\n",
    "Your tasks is to read through the chunk of a clinical note and classify different sentences as one of the following keys \"symptoms_labs\", \"thought_process\", and \"diagnosis\":\n",
    "symptoms_labs: \n",
    "- All references to symptoms they are currently or was experiencing, test results, or lab findings\n",
    "thought_process: \n",
    "- The reasoning, considerations, or requested labs made by the doctor\n",
    "diagnosis: \n",
    "- The doctor's final or working diagnosis, including the explanation or background of a diagnosis.\n",
    "\n",
    "Respond with a JSON **EXACTLY as structured:\n",
    "{'symptoms_labs': [sentence1, sentence2, ...],\n",
    "'thought_process': [sentence1, sentence2, ...],\n",
    "'diagnosis': [sentence1, sentence2, ...]\n",
    "}\n",
    "\n",
    "\n",
    "**Do not rephrase or paraphrase sentences. Use the original sentences exactly as provided.**\n",
    "<|im_end|>\n",
    "\"\"\"\n",
    "\n",
    "prompts = [f\"\"\"{initit_prompt}\n",
    "<|im_start|>user\n",
    "{chunk}\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\" for chunk in chunks\n",
    "]\n",
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0d9286a6-bd92-4ff7-a91c-bc51bf0c3dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a medical assistant helping organize a patient\\'s clinical notes  that will presented by paragraph/chunk.\\n\\nYour tasks is to read through the chunk of a clinical note and classify different sentences as one of the following keys \"symptoms_labs\", \"thought_process\", and \"diagnosis\":\\nsymptoms_labs: \\n- All references to symptoms they are currently or was experiencing, test results, or lab findings\\nthought_process: \\n- The reasoning, considerations, or requested labs made by the doctor\\ndiagnosis: \\n- The doctor\\'s final or working diagnosis, including the explanation or background of a diagnosis.\\n\\nRespond with a JSON **EXACTLY as structured:\\n{\\'symptoms_labs\\': [sentence1, sentence2, ...],\\n\\'thought_process\\': [sentence1, sentence2, ...],\\n\\'diagnosis\\': [sentence1, sentence2, ...]\\n}\\n\\n\\n**Do not rephrase or paraphrase sentences. Use the original sentences exactly as provided.**\\n<|im_end|>\\n\\n<|im_start|>user\\nA a sixteen year-old girl, presented to our Outpatient department with the complaints of discomfort in the neck and lower back as well as restriction of body movements. She was not able to maintain an erect posture and would tend to fall on either side while standing up from a sitting position. She would keep her head turned to the right and upwards due to the sustained contraction of the neck muscles. There was a sideways bending of the back in the lumbar region. To counter the abnormal positioning of the back and neck, she would keep her limbs in a specific position to allow her body weight to be supported. Due to the restrictions with the body movements at the neck and in the lumbar region, she would require assistance in standing and walking. She would require her parents to help her with daily chores, including all activities of self-care.\\n<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c37c65-b2f6-4639-8565-b7fb34328de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# responses = []\n",
    "# for prompt in prompts:\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "#     output = model.generate(**inputs, max_new_tokens=512, do_sample=False, temperature=0.0)\n",
    "#     response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "#     responses.append(response)\n",
    "#     if len(responses) < 3:\n",
    "#         print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "dd00851d-6cd0-4e27-ab14-3261b4b358d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def json_to_dict(full_response:str):\n",
    "    match = re.search(r'assistant\\s*(\\{.*|\\d+:\\s*\".*?)$', full_response, re.DOTALL)\n",
    "    json_data = None\n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "        try:\n",
    "            json_data = json.loads(json_str)\n",
    "            logger.info(\"Successful JSON parsed!\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            # print(\"Invalid JSON:\", e)\n",
    "            logger.warning(\"Invalid JSON, trying conversion\")\n",
    "            try:\n",
    "                pattern = re.compile(r'\\d+:\\s*\"(.+?)\"\\s*[:\\-]*>*\\s*(\\w+)', re.DOTALL)\n",
    "                json_data = {}\n",
    "                # print(json_str)\n",
    "                for match in pattern.findall(json_str):\n",
    "                    # print(match)\n",
    "                    sentence, label = match\n",
    "                    cleaned_sentence = sentence.strip()\n",
    "                    json_data[cleaned_sentence] = label.strip()\n",
    "                assert len(output) > 0\n",
    "                logger.info(\"Successful conversion!\")\n",
    "            except:\n",
    "                logger.error(\"Provided data schema not parseable/known, skipping this chunk\")\n",
    "                json_data = None\n",
    "    else:\n",
    "        logger.error(\"Nothing found, bad example!\")\n",
    "\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "336fbde5-3a9a-47bc-821f-bc770bfb6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in test[0]:\n",
    "#     # print(t)\n",
    "#     print(json_to_dict(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "43181f07-db68-42e8-a30e-cf8915de87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_example_idx = 0\n",
    "processed_dataset = {'sentence': [], 'class': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "0d2c8a82-2b93-48fc-a608-7e6e80caf1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7979"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(datasets['aug_med_notes']['full_note'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac3cbd4-ec2e-4710-ac92-acaef918748b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset:   0%|                                                                                                                                                        | 0/30000 [00:00<?, ?it/s]2025-05-30 18:08:21,688 || INFO || MedRL-CoT Setup - Preprocessing example 0\n",
      "2025-05-30 18:08:21,689 || INFO || MedRL-CoT Setup - Example 0 already complete, skipping\n",
      "2025-05-30 18:08:21,690 || INFO || MedRL-CoT Setup - Dumping to save\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91420cedf26e4df18b0776264ed9166e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 18:08:21,708 || INFO || MedRL-CoT Setup - Preprocessing example 1\n",
      "2025-05-30 18:08:21,709 || INFO || MedRL-CoT Setup - Example 1 already complete, skipping\n",
      "2025-05-30 18:08:21,710 || INFO || MedRL-CoT Setup - Dumping to save\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a87f09cb364a2e8f81ca0ffc835f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 18:08:21,727 || INFO || MedRL-CoT Setup - Preprocessing example 2\n",
      "2025-05-30 18:08:21,728 || INFO || MedRL-CoT Setup - Example 2 already complete, skipping\n",
      "2025-05-30 18:08:21,729 || INFO || MedRL-CoT Setup - Dumping to save\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce11e83b7e6a4ef28199ccf8136417a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 18:08:21,746 || INFO || MedRL-CoT Setup - Preprocessing example 3\n",
      "\n",
      "Classifying prompts:   0%|                                                                                                                                                              | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "# def preprocess_func(model, dataset):\n",
    "    # processed_dataset = {'symptoms_labs': [], 'thought_process': [], 'diagnosis': []}\n",
    "def process_example(example_note):\n",
    "    sentences = example_note.split('.')\n",
    "    chunks = example_note.split('\\\\n')\n",
    "    \n",
    "    processed_example = {'sentence': [], 'class': []}\n",
    "    \n",
    "    initit_prompt = \"\"\"<|im_start|>system\n",
    "You are a medical assistant helping organize a patient's clinical notes  that will presented by paragraph/chunk.\n",
    "    \n",
    "Your tasks is to read through the chunk of a clinical note and classify different sentences as one of the following keys \"symptoms_labs\", \"thought_process\", and \"diagnosis\":\n",
    "symptoms_labs: \n",
    "- All references to symptoms they are currently or was experiencing, test results, or lab findings\n",
    "thought_process: \n",
    "- The reasoning, considerations, or requested labs made by the doctor\n",
    "diagnosis: \n",
    "- The doctor's final or working diagnosis, including the explanation or background of a diagnosis.\n",
    "\n",
    "Respond ONLY with a valid JSON object **EXACTLY** with the sentence as key and the classification as the value: \"symptoms_labs\", \"thought_process\", and \"diagnosis\". \n",
    "\n",
    "**Do not rephrase or paraphrase sentences. Use the original sentences exactly as provided.**\n",
    "<|im_end|>\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    prompts = [f\"\"\"{initit_prompt}\n",
    "    <|im_start|>user\n",
    "    {chunk}\n",
    "    <|im_end|>\n",
    "    <|im_start|>assistant\n",
    "    \"\"\" for chunk in chunks\n",
    "    ]\n",
    "\n",
    "    responses = []\n",
    "    for prompt in tqdm(prompts, \"Classifying prompts\", leave=False):\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        output = model.generate(**inputs, max_new_tokens=1024, do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "        # output = model.generate(**inputs, max_new_tokens=1024, do_sample=False, temperature=0.0)\n",
    "\n",
    "        response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        parsed_dict = json_to_dict(response)\n",
    "        if parsed_dict is not None:\n",
    "            for sent, cat in parsed_dict.items():\n",
    "                processed_example['class'].append(cat)\n",
    "                processed_example['sentence'].append(sent)\n",
    "                # processed_dataset[cat.strip()].append(sent)\n",
    "        # break\n",
    "\n",
    "    return processed_example\n",
    "\n",
    "# processed_dataset = []\n",
    "\n",
    "for i in tqdm(range(0, len(datasets['aug_med_notes']['full_note'])), \"Preprocessing dataset\"):\n",
    "    logger.info(f\"Preprocessing example {i}\")\n",
    "    if i >= dataset_example_idx:\n",
    "        processed_example = process_example(datasets['aug_med_notes']['full_note'][i])\n",
    "        processed_dataset['class'].extend(processed_example['class'])\n",
    "        processed_dataset['sentence'].extend(processed_example['sentence'])\n",
    "        dataset_example_idx += 1\n",
    "    else:\n",
    "        logger.info(f\"Example {i} already complete, skipping\")\n",
    "    # processed_dataset.append(process_example(example))\n",
    "    # if i > 0:\n",
    "    #     break\n",
    "\n",
    "    \n",
    "    logger.info(f\"Dumping to save\")\n",
    "    processed_dir = os.path.join(os.getcwd(), medrlcot_config.data_dir, 'aug_med_notes', 'processed')\n",
    "    hf_dataset = Dataset.from_dict(processed_dataset)\n",
    "    hf_dataset.save_to_disk(processed_dir)\n",
    "\n",
    "# return processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "eb9c1e26-75f3-46b5-96b0-8bb82a6f20af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[274], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m processed_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maug_med_notes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull_note\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[254], line 50\u001b[0m, in \u001b[0;36mpreprocess_func\u001b[0;34m(model, dataset)\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[38;5;66;03m# processed_dataset[cat.strip()].append(sent)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;66;03m# break\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# return responses\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# processed_dataset = []\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[0;32m---> 50\u001b[0m     \u001b[43mprocess_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# processed_dataset.append(process_example(example))\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# if i > 0:\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m#     break\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m processed_dataset\n",
      "Cell \u001b[0;32mIn[254], line 36\u001b[0m, in \u001b[0;36mpreprocess_func.<locals>.process_example\u001b[0;34m(example_note)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m     35\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 36\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m     parsed_dict \u001b[38;5;241m=\u001b[39m json_to_dict(response)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:2597\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2589\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2590\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2591\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2592\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2593\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2594\u001b[0m     )\n\u001b[1;32m   2596\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2597\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2598\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2602\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2604\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2607\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2608\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2609\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2610\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2611\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2612\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2613\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2614\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:3560\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3558\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3560\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3562\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3563\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3564\u001b[0m     outputs,\n\u001b[1;32m   3565\u001b[0m     model_kwargs,\n\u001b[1;32m   3566\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3567\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/generic.py:969\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    971\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:690\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    686\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    687\u001b[0m )\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 690\u001b[0m outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    704\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/generic.py:969\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    971\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:423\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    421\u001b[0m     all_hidden_states \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (hidden_states,)\n\u001b[0;32m--> 423\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_layers.py:48\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:244\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:164\u001b[0m, in \u001b[0;36mMistralAttention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    163\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[0;32m--> 164\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_position}\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:88\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[1;32m     86\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[1;32m     87\u001b[0m q_embed \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(q) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[0;32m---> 88\u001b[0m k_embed \u001b[38;5;241m=\u001b[39m (k \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (\u001b[43mrotate_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:58\u001b[0m, in \u001b[0;36mrotate_half\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     54\u001b[0m         down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrotate_half\u001b[39m(x):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Rotates half the hidden dims of the input.\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, : x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# processed_dataset = preprocess_func(model, datasets['aug_med_notes']['full_note'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "78048fde-1e41-4a61-a197-d69de829a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n"
     ]
    }
   ],
   "source": [
    "print(len(processed_dataset['class']), len(processed_dataset['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50563881-d753-409e-98a0-e460c1743b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(test['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21fc190-eaf3-4490-a8b5-5194022233a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23fe30b-9625-4b50-ae76-8eaf5568407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd125701-4272-4cb0-b676-af6120f0bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset.from_file(os.path.join(processed_dir, 'data-00000-of-00001.arrow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "087c6fec-9588-4541-b5c9-36374488d08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/medrlcot/data/aug_med_notes/processed'"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7067d17e-480c-48bc-8f47-50856a9f20e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A 47-year-old male patient was referred to the rheumatology clinic because of recurrent attacks of pain in both knees over 1 year.': 'symptoms_labs'}\n",
      "{'In September 2016, the patient presented with severe pain over the medial aspect of the left knee for a two-week duration which prevented him from ambulation.': 'symptoms_labs', 'The pain increased with weight-bearing physical activity.': 'symptoms_labs', 'The patient reported no history of trauma before the onset of the knee pain.': 'symptoms_labs', 'Examination showed severe tenderness over the medial side of the knee with mild effusion and moderate limitation of range of motion.': 'symptoms_labs', 'There was no erythema or increased warmth of the knee.': 'symptoms_labs', 'MRI of the left knee showed a moderate-sized focal area of marrow edema/contusion involving the medial femoral condyle in mid and anterior parts predominantly along the articular surface.': 'symptoms_labs', 'The patient was prescribed diclofenac sodium 50 mg twice daily and was advised to avoid prolonged weight-bearing activities.': 'symptoms_labs', 'Over the next few weeks, the pain subsided and resolved.': 'symptoms_labs', 'Three months later, the patient developed spontaneous new onset of pain involving the lateral aspect of the same knee.': 'symptoms_labs', 'MRI showed bone marrow edema involving the lateral femoral condyle with complete resolution of the bone marrow edema of the medial femoral condyle.': 'symptoms_labs', 'He was treated conservatively with NSAIDs and physiotherapy and advised to use a cane to minimize weight bearing on the diseased knee.': 'symptoms_labs', 'demonstrates MRI of the left knee in September 2016 and three months later.': 'symptoms_labs'}\n",
      "{'In April 2017, the patient developed gradual pain over the medial side of the right knee with no obvious swelling.': 'symptoms_labs', 'MRI of the right knee showed a moderate-sized focal area of marrow edema involving the medial tibial plateau medially and anteriorly.': 'symptoms_labs', 'The patient was treated conservatively in a similar fashion to the previous episode.': 'thought_process', 'Four months later, the pain got more severe for which he underwent another MRI of the right knee which showed extensive marrow edema involving the medial femoral condyle with complete recovery of the medial tibial plateau bone marrow edema noted in the previous MRI ().': 'symptoms_labs', 'The patient also recalled a similar pain happened in 2011 to the left knee but did not do MRI at that time.': 'symptoms_labs'}\n",
      "{'In all previous presentations, the patient did not report any history of trauma, fall, twist, constitutional symptoms, or using corticosteroids.': 'symptoms_labs', 'He also had no history of other joint involvement apart from knees and denied any history of low back pain.': 'symptoms_labs', 'He did not have any features suggestive of spondyloarthropathy or connective tissue disease.': 'symptoms_labs'}\n",
      "{'Past history is significant for fracture of the greater tuberosity of the left humerus and undisplaced fracture of the left cuboid bone. Fractures happened after he fell off a ladder.': 'symptoms_labs', 'Also, he is known to have mild asthma which is controlled with as-needed bronchodilator and hypertension maintained on amlodipine 5 mg daily.': 'symptoms_labs', 'The patient had never been a smoker or an alcohol consumer.': 'symptoms_labs'}\n",
      "{'Lab investigations revealed vitamin D 8 ng/mL (normal: >30 ng/mL), corrected calcium 2.16 mmol/L (normal: 2.10–2.60 mmol/L), parathyroid hormone 91 pg/ml (normal: 15–65 pg/ml), and alkaline phosphatase 49 U/L (normal: 40–150 U/L)': 'symptoms_labs', 'Complete blood count, kidney and liver function, CRP, and ESR were within normal limit.': 'symptoms_labs', 'Immunology profile including rheumatoid factor, ACPA, ANA, anticardiolipin, and B2-glycoprotein were all negative.': 'symptoms_labs'}\n",
      "{'DXA scan showed a T score of −1.0 at the lumbar spine and −1.6 at the left femoral neck suggestive of osteopenia. shows further details of the DXA scan.': 'symptoms_labs'}\n",
      "{'The patient was treated conservatively with oral vitamin D2 50,000 IU/week supplement and NSAIDs.': 'diagnosis', 'Gradually, the symptoms subsided over the next few weeks, and vitamin D level became normal after 12 weeks.': 'diagnosis'}\n"
     ]
    }
   ],
   "source": [
    "# for t in test[4]:\n",
    "#     print(t)\n",
    "#     # print(json_to_dict(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f9370604-994c-4fed-a3c2-9b8e1d428fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "288bc46c-0980-4ac9-8184-1ac448b2e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Load model (adjust to your chosen model)\n",
    "# model_id = \"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     device_map=\"auto\"\n",
    "# )\n",
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# from transformers import LlamaTokenizer, MixtralForCausalLM\n",
    "# import bitsandbytes, flash_attn\n",
    "\n",
    "# tokenizer = LlamaTokenizer.from_pretrained('NousResearch/Nous-Hermes-2-Mistral-7B-DPO', trust_remote_code=True)\n",
    "# model = MistralForCausalLM.from_pretrained(\n",
    "#     \"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\n",
    "#     torch_dtype=torch.float16,\n",
    "#     device_map=\"auto\",\n",
    "#     load_in_8bit=False,\n",
    "#     load_in_4bit=True,\n",
    "#     use_flash_attention_2=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff3ff0-e767-4832-908e-84f923261c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
